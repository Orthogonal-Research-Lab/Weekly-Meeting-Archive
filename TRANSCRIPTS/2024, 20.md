
Transcript
0:00
hello hello hi hello Susan hi Hi how are
0:06
you hello Morgan too bad I yeah I was on earlier but um anyway I had to turn my
0:13
computer off turn it back on so I get sound oh that sort of thing yeah I know
0:20
yeah welcome uh Susan how was how was everything going for you oh I'm messing
0:27
around with my models okay okay and
0:33
um I've discovered that well I know about
0:39
integrating the data from points and or adding
0:45
them and I don't know exactly what it's doing because it does these iterations
0:50
and I swear it's adding the iterations up like the movements so I
0:57
put um a a point that's further out to see how the movement of the outer part
1:04
of my structure went and it Mo moves like 0.2 millimeters or something like
1:12
that which is good like that's kind of the right the right amount no it's it
1:18
was actually I don't know it was the right amount anyways and um the inner part just moves
1:28
all over the place I swear just adds up how much it moves so I'm getting some
1:35
very weird data um try it on some very simple
1:42
structure yeah well I tried it out on my triangular prisms and it seems to work
1:49
there but um basically my tcity
1:54
structure in the middle of my diagram collapses it collapses like this
2:01
and then it moves like this all over the place so I don't think that's the good
2:08
point to to look at I just wondered how much the
2:13
iterations played into into this anyway I gotta figure it out yeah what program
2:21
are you using again console okay is a console thing well yeah
2:30
it just automatically does doeses these things I didn't ask it to do iterations
2:36
yeah sometimes it ca it causes it to oscillate oh yeah
2:42
yes can you control step size um no it does that it controls the
2:49
step size um and the damping and damping and
2:54
step size and tries all these different things in the meanwhile my my poor models bouncing off all over the place
3:02
yeah I actually got um programmed to do an AI
3:08
lamp on UD Demi the other day and uh yeah you can program it into
3:16
um what oh the ardino okay yeah guy with arino now okay yeah so that's great uh
3:26
dick sent me a draft of a uh the Pearl and noise chapter so I'll look that over
3:32
today and try to address everything duplicated figure okay yeah that's fine
3:41
yeah all right uh hello Jesse and
3:47
Morgan uh if you had anything you wanted to say or
3:56
update okay well U uh so let me get started up there's Pocky
4:07
hello so I have a few things to get started with and then maybe we'll get into an update from
4:14
Pocky uh so let me share my
4:20
screen so one thing you know we've been doing is exploring different uh types of
4:26
programs and software and I've been talking with Hussein in different a different meeting about different types
4:33
of Open Source software you can use to do multiphysics because commo is
4:38
proprietary thing and it's not necessarily good for you know everything
4:44
or sometimes the things we want to do so you know looking for different packages
4:49
that might you know replace that and do what you wanted to do is a good exercise
4:54
and so Hussein's been looking over things uh he's been identifying different packages that might be useful
5:01
for doing the kinds of things he's doing with dick on I did I did find something
5:07
in that lab it's called steady okay uh for doing 10 seconds oh W find I haven't
5:15
explored it yet yeah yeah I didn't want to go over the
5:21
repositories for two packages actually they're both by from Google Deep Mind and one of them was something that
5:28
Morgan highlighted and brought to my attention the other one is something we've talked about in
5:33
the group so this first one is something we've talked about I think Morgan talked about in the group a number of times
5:39
it's called Moko and this is multi-joint Dynamics with contact a general purpose physics
5:46
simulator so this is the repository that they have um so they have the software
5:52
available uh they have uh their latest releas is 3.1.6 and you know you can Fork it and
5:59
and and you know do things with it accordingly so this is uh basically this
6:04
is a a physics simulator it's a general purpose physics engine so you know it's
6:09
comparable to some of the physics engines we might use it's not specialized for developmental biology
6:15
but it is specialized for this sort of multi-joint Dynamics work so this is
6:20
something that um you know they've developed this um it's this repository is maintained by Google Deep Mind so
6:28
they're using this and some of their research and they've made it open for people to I guess contribute to fork or
6:35
whatever so what is a joint uh it's where you have two rigid bodies and
6:42
there's a connection between them and you can uh you know things it it articulates around the joint so like
6:49
your arm has uh three joints your wrist your uh your uh what is that the elbow and
6:59
then the shoulder and so uh yeah that's a three-joint system and you could
7:04
articulate your arm like that if you were an octopus you'd have many more joints which are just the different yeah
7:13
is the pendulum um yeah yeah it's it's a pendulum would have like one joint or
7:19
two joints at the top yeah and if it has more than one joint or even if it has
7:24
one joint um it's um it can be chaotic in nature
7:30
yeah it does produce chaotic Dynamics uh if you run it just kind of
7:35
yeah so uh yeah this is uh so this is a
7:41
Capi and is intended for researchers and developers the runtime simulation
7:46
modules T to maximize performance and operates on low-level data structures uh the LI Library includes
7:53
interactive visualization with a native guey and it Expo it exposes a large
7:59
number of utility functions for computing physics related quantities so it's gen it's a General Physics tool but
8:06
it operates on this uh principle so this is uh read the docs here and um you you
8:13
can set it up on your machine or run it in a collab notebook and to do some basic tutorials so you can do things
8:20
like lease squares solving mjx which is uh Jack's
8:26
implementation differentiable physics uh where you have Locomotion policies with
8:31
analytical gradients so you're doing this sort of uh like sort of deep learning esque type differentiable
8:39
learning type physics so you can run that in a collab notebook as well so you
8:44
know this is where you're maybe trying to optimize a system and uh do things
8:49
like that so yeah this is the I don't know if you can hear me but yeah you can
8:56
yeah okay uh everything's frozen here so I'm going to go out come back
9:01
in okay that's okay yeah
9:07
right that is uh mojoko and then uh there's this other
9:12
repository called torax this is also uh managed by Google deep mine this is Tok
9:20
toac transport simulation in Jax so they're using Jax which as a language to
9:26
uh sort of make this stuff work uh this this is uh version 0.1.0 and I think
9:32
this is the one that uh Morgan pointed me to in a different venue so uh this is
9:40
uh what is torax it's a differentiable tokomak course transport simulator aim
9:45
for fast and accurate forward modeling pulse design trajectory optimization and
9:51
controller design workflows so it's a lot of like uh physics where you're doing things like looking at forward
9:58
modeling and trajectory optimization so um so there again there's a read the
10:05
docks uh they use Jacks here uh to provide Auto differentiation
10:10
capabilities and code compilations for fast run times differentiability allows
10:16
for gradient-based nonlinear PD solvers fast and accurate modeling so it is a PD
10:22
that they're working with uh and then for sensitivity analysis of simulation gradients to arbitrary par parameter
10:30
inputs um and so Auto differentiability allows for these applications to be
10:35
easily extended with the addition of new physics models or new parameter inputs by avoiding the need for hand derived of
10:43
Cobian so you don't need to hand derive jacobians to use this you can use the
10:48
differentiable tools in here differentiability Tools in here to do some of the math on that so they offer
10:57
uh different types of physics in this package coupled PDS for ION and electron
11:03
heat transport electron particle transport and diffusion of currents they
11:09
have finite volume methods and multiple types of solver so PD solvers come in
11:15
different flavors you can use different ones depending on which you think is best uh they have a lot of electrical
11:21
engineering type stuff like omic power ion electron heat exchange fusion
11:27
power um and then time dependent boundary conditions and sources uh then they offer also
11:35
geometries uh for the problem space and um yeah so they have a lot of
11:42
different tools for physics I don't know if this is considered multiphysics but they do have a lot of tools for
11:48
like uh you know different sorts of electric currents and flows and things
11:55
like that so this is an interesting tool um you know we might look into this as
12:00
well again this is the same as with maoko you can Fork it and use it as you
12:06
would like so yeah that's that's all I'll say
12:11
say about those two repositories maybe we'll find those useful in some
12:17
way uh the next thing I want to talk about is this milestones and developments this is something I found
12:24
this is a nature portfolio thing where I guess they curate their articles and their archives so nature of course has a
12:31
lot of journals and they have a lot of things that have happened over like the hundred and some years well I think
12:38
Nature's in publishing a lot longer than that but maybe this is about a hundred years of Developmental biology while
12:44
still it's like so they've Nature's been sort of at the Forefront of this area
12:50
and uh they in this set of Articles uh these are what they call Milestones they
12:56
have a paper that lays out the history of different findings in developmental biology so um you know they have these
13:04
different Milestones numbered in in chronological order so it goes from
13:09
1924 which are the organizing principles uh
13:14
1929 taking a leaf from the book of Sate so this is about Sate this is about
13:20
organizing principles and embryos um 1952 symmetry breaking and computer
13:27
simulation uh so let's look at that one to see how they kind of do this uh so this was a
13:34
paper by Christopher surage in nature reviews Neuroscience
13:39
2004 and this article talks about this work this line of work that goes back to
13:46
Allen tur's chemical basis of morphogenesis so that was in
13:51
1952 and then you know they kind of go through the significance of that paper
13:57
and that finding and then they kind of go through the subsequent history so you know what were
14:03
what was churn trying to do and so he was trying to discover how the symmetry of a homogeneous mass of
14:10
identical cells could be broken to form a particular pattern of two or more
14:16
spatially distinct cell types and so this is something where we we kind of call the Symmetry breaking now but at
14:23
the time this was the problem he was working so he came up with this idea of more morphogens and then as we'll see in
14:31
this collection the discovery of actual morphogens came later but this gives you
14:37
this historical framework or this theoretical framework back in history and then being able to frame yeah it's
14:45
might well be nonsense and look into the angel fish a picture of angelish there
14:51
okay and I I figured that the pattern is due to cell movement not to the detur
14:59
yeah oh okay yeah well I don't know I mean it's a thing about findings yeah
15:06
you know people build these edifices without looking at what the fish actually do
15:14
yeah so yeah then this follows this idea through uh and then uh they basically
15:23
say this is that is not to say turing's original proposal wouldn't work so this was where
15:29
sort of Turing did this work and then there were people who kind of built upon it uh in the area of reaction to Fusion
15:37
models uh and you know there are different cases of this now where we have different types of reaction
15:44
diffusion models and you know so people refin the idea more and there different
15:50
mechanisms that people proposed and so here it says that is not to say turn's original proposal wouldn't
15:56
work in the early 1990s purely chemical systems producing Turing patterns were
16:02
developed and five years later a natural Turing pattern was found on the skin of an angel fish and that's a paper that um
16:09
where they that's the reference of the angel fish uh and then however the
16:15
significance of turing's paper is not in what it says but rather for its demonstration that development could be
16:21
approached in a quanti quantitatively rigorous fashion so that angelfish article actually is
16:29
uh see in 1995 I believe this condo on aai
16:36
a reaction diffusion wave on the skin of a marine angel fish so that's the article where they talk about the
16:42
angelfish being a turing pattern and I don't know that's the that's a paper
16:47
that exists I don't know if they're correct or yeah you know it's sort of like crack patterns and mud can be due
16:54
to all all sorts of different phenomena yeah even though they look similar
17:01
yeah the other problem with tering which I published an article on is that it's
17:08
good for one step of differentiation but if you go two steps it falls apart
17:22
yeah all right um and so going back to the uh collection
17:29
you know we've got things kind of from the early years at these milestones and then we're going out later so you know
17:37
there's this one from 197 or this milestone in 1977 systems biology ahead of its
17:46
time and this is based on a paper by Magdalena Skipper in nature reviews Neuroscience in 2004 so in this
17:56
paper uh this this is kind of getting into so this was sort of the beginning
18:01
of the genomic age um and this is actually about John solon's work in
18:08
celegans embryos so this was the paper on sort of in
18:13
1977 where John solsten worked out the uh lineage tree for sea elegance and so
18:19
the story goes is that John Solon sat at his microscope with a piece of paper and
18:24
Drew the lineage tree out and published lineage Tree in
18:30
1977 and you know it's like really celebrated that's one of the reasons why
18:37
people work on C Elegance because there's this regularity in the lineage tree and you know you have a good set of
18:44
uh data there and so this kind of builds from this paper uh they wanted to build
18:51
the uh determine an entire cellon age of celegans and so work on the worm had
18:57
something systematic about from the beginning it's exemplified by its conscious Choice as a model so Sydney
19:03
brener back in the 60s proposed that we use celegans as a model organism for different reasons uh you know looking at
19:11
disease looking at development looking at other types of biology and the argument was is that cgans is easy to
19:18
culture has a small number of cells but also has this deterministic number of
19:24
cells in adulthood and has this very easy to understand uh development relative to other species
19:32
so all those attributes were why they wanted to work on celegans uh and so you know there was
19:38
this whole group of people who wanted to work out the details of celegans so that
19:44
we could use it as a model organism so this was the Solon uh work in
19:50
1977 then there was another paper in 1983 where Solon and horvitz worked out
19:56
the uh post embrionic lineage of of uh the the uh of the lineage tree and that
20:03
are the that that that refers to the fact that there's 671 cells in this
20:10
newly hatched uh worm in the L1 stage and of course there are more cells in
20:16
the adult so you gain about 300 cells in the post embrionic phases of development
20:22
in the uh larval developmental stages and so this is where you get this
20:27
hatching uh at post hatching uh cell division and differentiation and so they
20:34
they worked out the tree here as well um and so this is this is kind of
20:40
celebrating this work uh and then she asked the question so should we push back the birth date of systems biology
20:47
by some 20 years it might seem fitting to think of John solsten as a pioneer of this approach after all he was to go on
20:55
to be one of the early champions of the Human Genome Project and subsequently one of the leaders of the publicly
21:00
funded International Consortium so aside from a lot of the stuff that we know on SE elegans in
21:07
terms of lineage trees and cells and other things we also have a full genome
21:13
sequence and those efforts really were sort of uh you know worked out in seans
21:20
and you know seans is a good example of you know another genome that's been fully sequenced and it was sequenced
21:26
pretty early with respect to you know the history of sequencing so you know
21:31
the argument here is that this was sort of the first sort of attempt at systems biology and so that's um that's another
21:40
Milestone so there are a lot of articles in here uh on different things going on in developmental
21:46
biology um let's see if I can find another one um this one is Sonic Hedgehog the
21:54
morphogen this Milestone was in 1991
22:01
so this is uh this is about this these sort of
22:06
morphogen gradients and so this kind of follows from uh turing's work in the 50s
22:12
but this is where they're actually trying to discover some of these molecular underpinnings of uh induction cell you
22:19
know tissue induction and morphogenesis so this talks about uh
22:26
induction uh with morphogens like Sonic Hedgehog so the idea of morphogens was
22:31
kind of theoretical at the time that turn proposed them but this is then they actually found morphogens in
22:38
developmental biology later on Sonic Hedgehog being one of the first examples of that so this is a Sonic Hedgehog
22:46
gradient uh this defines uh different domains of motor neurons and uh four classes of
22:53
interneurons so it's this gradient that defines you know different types of cells in a
22:59
tissue um so this talks about uh patterning of this central nervous system along the dorsal ventral axis
23:07
that's from top to bottom uh specifying motor neurons and the vental half of the
23:12
spinal cord and sensory neurons in the dorsal half this happens just as the neural plate is folding along the
23:19
midline to form the neural tube so as the neural tube is closing and so they they' they have this uh model system
23:26
that they used to uh discover Sonic Hedgehog and its mechanisms and this
23:32
dates back to the90s 1991 so very early on in the 1990s
23:38
Jessel and colleague set out to test whether signals from the notic cord or floor plate which are anatomical
23:43
structures might be responsible for controlling the dorsal vental pattern of neuronal differentiation so this is in
23:50
the in the brain uh where this is in the vertebrate brain where they're showing this and they're they're you know trying
23:58
to discover this uh factor that that is responsible for this so this is where
24:03
they're looking at the chick embryo specifically they showed that both the noord and the floor plate could induce
24:10
ectopic patterns of ventral motor around layers furthermore removal of the noord
24:15
or floor plate resulted in the loss of these ventral motor neurons so both noord and floor plate cells could
24:22
release signals that are required for the initial dorsal vental patterning of the central nervous system and so
24:28
induction by a noord and the floor plate explants that they prepared resulted in
24:34
distinct subsets of neuron types at defined distances so it's not just about
24:39
you know different cells differentiating into different things but there's a spatial component as well and so the
24:46
authors proposed a model from all these findings in which a diffusible signal produced in the noord or the floor PL
24:54
results in a gradient of the signal across this dorsal ventral axis and this gradient then is responsible
25:00
for the pattern of neurons induced so this is where they kind of get into this and then there was another breakthrough
25:07
uh later on that came from the cloning and vertebrate hom uh homologues of the drosoph segment polarity Gene Hedgehog
25:15
so the dropa embryo has these stripes and these are segments that turn into
25:20
different parts of the of the fruit fly and so there's this Gene Hedgehog and
25:27
they clone this the homologue of this in vertebrates which is this or in in the I
25:34
guess in the Czech embryo example uh which is this polarity Gene Hedgehog two
25:40
groups simultaneously clothing these homologues McMan and colleagues in the mouse and anaman colleagues in zebra
25:47
fish so they did this in Mouse and zebra fish in in these vertebra um spey model
25:54
organisms um in both cases the expression pattern of
26:00
one hom homologue in particular Sonic Hedgehog so there is this polarity Gene
26:05
Hedgehog under sofa and then they found the homog and they called it Sonic Hedgehog where that was at least the
26:11
name that they gave it because at the time that was a popular uh character in a video game implied that it might be
26:19
involved in ventral CNS patterning essay's shh or Sonic Hedgehog was
26:24
expressed in both the no de cour and the floor plate at the appropriate times in development that were expected for the
26:31
inductive signal so they assumed that this was the mechanism for or topic
26:36
expression of shh could induce floor plate specific genes Sonic Hedgehog was
26:41
predicted to be a secreted protein so was obious an obvious candidate for the diffusible signal that was predicted
26:48
earlier in the studies of uh of Zer fish so uh subsequent work has shown the
26:55
differentiation of the floor plate might be more complex so you know they have these initial studies they show these
27:01
mechanisms they work out the genes that are involved but then you know as as uh
27:06
time goes on we discover the complexity of that mechanism and you know we end up
27:13
with but we have this basically we have this history of this finding and where it comes from so all of these Milestones
27:21
I like the way this is organized and these different milestones and uh you know this the date here in parth es is
27:28
the date where this discovery was made it stops at 1997 uh but you know it's still pretty
27:36
useful in terms of framing some of these ideas and their sort of their
27:41
intellectual lineage and what it's l us to so it's a very good collection of uh
27:48
papers um let me grab a copy of this and put it
27:53
in the chat right
27:59
here and that's the paper if you're interested and it looks like dick posted
28:05
something on let's see uh part three the reverse engineering road to Computing
28:11
life walking the tight RPP chapter 10 the dilemas of hierarchical instabilities Turing morphogenesis
28:18
that's what he was talking about earlier that reference so this is from the once
28:23
in future tring Computing in the world computing the world so this is a colle ction I believe of different papers sort
28:30
of celebrating turing's Legacy is that correct yeah I think had a sentennial oh
28:37
okay yeah okay so that's great um so any
28:45
questions at this
28:53
point okay I have a nice lecture that I found on
28:59
um YouTube okay about
29:05
um paraday instability and floating drops okay
29:11
um I'll find the url and just um put it
29:17
in here okay if if you want it yeah it looks good or it sounds good yeah it it
29:25
was interesting so I'll just put it in there for everybody's interest
29:31
yeah that's great thank you uh
29:37
see we had another uh thing in the chat here dick has this once in future
29:42
touring book so you can take a look at that as well um so Pocky how are
29:52
you hi hello I'm G how are you guys pretty good
29:59
yeah so today I wanted to share like I have come up with some idea of how I
30:05
will be proing with the graph M networ and I had some questions as well so I'll
30:11
just share my screen
30:20
okay uh yeah
30:26
so uh so basically uh this was the this is the architecture of the neural
30:31
development program so uh we start with some nodes which are given at the
30:37
beginning and then we have like performed some convolution operation and
30:43
then comes like a multier perceptron which determines where we will add the nodes and then we have a weight
30:50
prediction MLP which will determine the edge base and a and then another cycle
30:56
will start so uh in the de repository I came across a
31:01
few data sets one had
31:09
uh yeah uh this one it has like the coordinates
31:15
and this data set has like bir and de timings of various cells so uh what I
31:23
plan to do is that uh for the MLP I will give uh
31:28
the time stamps which will determine when to add which nodes and where to add will be determined by the
31:35
lineage for example like cells which have the same parent their string names
31:40
have like the same they have the same substring only the last character is changed is what I understood by looking
31:47
at the data set uh like for example over here it's a a l and four * a yes and
31:54
then it will be divided into r or l so I was thinking I could use that and give
31:59
that to the MLP which it will use to add new nodes and then uh model can assign
32:07
like model can learn to predict the edge weights and then when uh weights are added we will already have like uh with
32:15
the help of this uh X and Y coordinates we can basically uh compare the two and
32:21
calculate the loss if it predicted like currect rates like cells that are closed
32:27
by should have more should have like lesser distance compared to the ones which are further away and with the help of that it will
32:34
update like the edge so we will uh cross check them and like calculate the loss and then the loss will be that
32:40
propagated so that the network can learn that uh model can learn that so I had a
32:47
question about this as well like uh after going through various articles and
32:52
all I came up with these following parameters which can be like learnable
32:57
parameters for the model like I mentioned it can update it can learn how to update the edge weights which can be
33:03
like the cell cell interaction Str basically the cell that are closed by will have more influence on each other
33:10
compared to the cell that are further away and we can also make the special coordinates itself
33:17
as the learnable parameter to determine which cell which will get generated
33:23
where and we can also learn like the division findings or we can on the division probabilities whether the
33:30
division is symmetric or asymmetric uh this basically means in like in the beginning of the cell
33:36
division like at the CYO stage of C basically it has asymmetric division
33:43
which means the P0 cell divides into ab and P1 and they will have completely
33:49
distinct BS like AB will further divide into more similar cells which are basically which will generate uh
33:58
contribute to the growth of the organism and the P Zer are like a separate set of
34:03
cells so uh this can be determined and there is also this thing called gene
34:10
expression level I'm not sure I understood it fully that's why I've written I would need to look more into
34:15
it but it basically determines the fate of the cell and whether it like the type
34:21
of the cell whether it will develop to become a neuron or a muscle cell or an intestinal cell so this is what I
34:29
understood from what I did but like these are the parameters which on which the model could be trained to learn so I
34:36
wanted to ask which one would be the best as per the requirement okay so yeah we know celld
34:44
division timing is known in C elegan so that's actually not something we need to learn per se although we can do some
34:52
very interesting experiments where we vary the cell division timing or we
34:57
change the parameters of the model and we you know like the the data about the the cells and their daughters we can
35:04
play with the timing to see what happens but we do have the cell division timing we can you know s do the simulation to
35:11
see if it matches the data so that from a benchmarking standpoint that would be
35:16
a good thing to have you know to look at because we know kind of what it should be and we can then do the simulation and
35:23
see if it matches uh so that's one thing the cell interaction strengths are you know it's
35:31
it's an interesting question because there's a lot of there are a lot of different signaling mechanisms uh like
35:36
in one of the articles I talked about they did these things with diffusible proteins or diffusible signals and so
35:43
that happens a lot in cells where you have these uh you know diffusible
35:49
signals that serve to organize groups of cells and so that's a little harder to
35:54
get information on I don't know of any good data sets where they look at diffusable uh substances proteins
36:02
whatever and celegans but we do have the distances between the cells and that uh
36:07
speaks to the third point which is spatial coordinates so if you remember from last week we have the data set that
36:14
I was going through um and I was talking about the different XYZ coordinates that
36:20
we have those XYZ coordinates can serve as sort of like a you know way to kind
36:26
of gauge interaction strength maybe the potential of interaction and you know again we can do
36:32
things like we can create like a scenario where one cell was diffusing something and build a model of its Decay
36:40
linear Decay and then see which cells are sort of influenced by that so we
36:46
don't have direct data on those inter interaction strengths but we can
36:51
actually infer them from modeling you know like taking those coordinates using
36:56
it as a center point that cell at the center point then diffusing some signal there's a linear Decay and then whatever
37:04
cells are within that cone are influenced and the cells that aren't in
37:09
in that cone are not influenced or they're influenced to a certain degree so that that might be something
37:15
interesting we could actually just have that could be more of a modeling exercise since we have both the cell
37:23
sort of you know an approximation of the location and sort of the distance of
37:29
cells and we can determine those things so we have that we have spatial coordinates spatial coordinates are not
37:36
I mean now these are just inferred from experiments and it's you know we know
37:41
then celegans cells tend to end up in a certain location relative to other cells
37:47
so the actual location is a little tricky because it's a a centroid value
37:53
but basically we know from like microscopy that like the ab cell should
37:59
be at the anterior end P1 should be at the posterior end and then the divisions
38:05
you know they the cells will sort of be in the same vicinity of like so ABA and
38:11
ab uh L will be in the same uh vicinity they'll just be in different locations
38:18
so we kind of know where things should be so we do have those spatial coordinates they estimates or
38:24
approximations of actual location but we know kind of where they should be and so
38:30
we can actually um you know we can actually do experiments where we say
38:35
what if we get rid of a couple of cells can we build a an a sort of a f embryo
38:41
that has like uh cells that kind of shift their position based on the loss
38:47
of other cells in the UMO or things like that so we can have like actual oh uh
38:53
Susan set of rally in stability so we can actually have a full you know a full set of cells in
39:00
those positions where we can sort of estimate what happens if they get moved around or whatever introduce different
39:07
perturbations and see what happens uh Susan you said Raleigh and stote what were you
39:12
thinking um that just goes with the my post there the YouTube post that's all
39:19
oh okay I I should have Ed it as title for it oh so it's backwards that's all
39:25
sorry yeah uh and then division probabilities yeah symmetric and asymmetric again in seans those are sort
39:33
of known we have the tree we know kind of where those occur but again we can use that to validate the model to
39:41
predict so with seans we're actually quite fortunate because we have all those we have a lot of information about
39:48
that and the model should predict those things uh but then we can also extend the model to say okay what happens if
39:55
there's you know if we have say a genetic mutant where they have they're missing some cells in development or
40:02
there's some differences in how cells are signed we can work backwards and do those
40:08
things so those four things are very useful I think they're they're all doable we have data on them again
40:15
they're approximations of what's actually happening in a in a embryo in a seelan embryo and there's variation but
40:22
we can definitely work from them now this fifth one is interesting because we don't don't have a lot of really good
40:29
data on Cell by cell gene expression we have like you know partial data we have
40:34
data from different time points and sometimes it's averaged over a bunch of cells but basically what we're
40:40
interested with there is like each cell is going to have a gene expression level for a some marker and so this is
40:48
something that you know we can get data on for actually for the the data set
40:53
that we have the one um uh the one where we were talking about last time with the
40:59
cell positions cell tracking data um Waton at all um they were doing this uh
41:06
they they use these markers to Mark each cell basically a a fluorescent marker
41:13
and you know there's a gene I think associated with the gfp marker and so they do have those that kind of
41:20
expression and while it doesn't tell you anything about differentiation it can tell you you know
41:25
it can give you some information about genes being expressed in different cell types so there there things like that we
41:32
can do to sort of uh calibrate that and of course we can model certain scenarios
41:38
again we can say you know if there's a gene that's being expressed and something that's being uh
41:44
differentiated uh what should that look like so that yeah that needs a little bit more worth thinking out on how to
41:51
approach that but I think the first four parameters would be good and you can actually tune those to to the data so
41:58
that's good we have the data on us all
42:03
right thank you fors yeah so did you is that all you
42:09
wanted to say or yeah yeah I wanted to like uh ask which would be more relevant
42:16
so I think I got some information on that yeah I will let you know what I've
42:23
planned in the next meeting okay yeah yeah I think I would start pretty simply
42:29
you know I'd maybe start with um well I I don't know I don't know which one to start with first that might
42:36
be um yeah also you mentioned that you
42:41
had like a you discussed our paper related to interaction steps which
42:47
talked about diffusible substances and all that could you please share that one yeah yeah I don't I guess I don't know
42:55
if it's a single paper but I can I can share some materials on that yeah I mean you know it's it's again uh we have a
43:02
lot of data in seans and we can use those to sort of calibrate our models um
43:09
but you know it's it's a it'll be interesting to see how how it works I like this method that she's uh found
43:17
this is a method that was published of course recently where they're doing these neurodevelopmental programs and
43:23
you know I think the idea is that you're able to custom them um you know in a way
43:31
for different organisms or different contexts so this is a slides and above this is uh walking the tight rope yeah
43:39
so this is for this article okay so the final thing I want to talk about
43:45
today something that Morgan again shared and I thought it would be I I've been
43:50
wanting to do this for a while but this is a paper uh that was published
43:55
recently in cel systems and this is a I guess it's a
44:01
hypothesis paper perspective they call it it says un knowing a gene a
44:06
distributional hypothesis of Gene function so these uh authors are from
44:13
the Bro Institute at MIT and Harvard Dana Farber Cancer Institute basically
44:18
the Boston uh group and uh so this is I
44:24
guess a computational approach to uh looking at genes and Gene function
44:30
and cells so the summary of this reads as
44:35
words can have multiple meanings that depend on sentence context genes can have various functions that depend on
44:41
the surrounding biological system so you know they're kind of drawing from this
44:46
analogy between sort of these uh
44:51
sequential uh symbolic systems like words and sentences and also then
44:58
they're drawing a connection with genes and their function and the surrounding biological
45:04
system this pleotropic nature of Gene function so when they say pleotropic
45:10
they mean that a single Gene can have multiple effects so you can't just say that one gene corresponds to one
45:17
function or one gene corresponds to some trait you have to think about not only
45:24
that they're multiple genes contributing to to a trade or a function but that
45:30
that one gene can have multiple effects depending on how it's regulated so that's what they're getting
45:36
at here this pleotropic nature of Gene function is limited by ontologies which
45:42
are annotations of Gene functions without considering biological contexts
45:48
so this ontology term is based on what they call uh Gene ontologies so in the
45:55
data set that Pocky show um you know we have cells and those cells you'll notice that there was a
46:02
column where there were a lot of words there were sentences those sentences are the annotations of each cell and so you
46:09
have these for genes but you have them for cells and seans and these ontologies are basically ways of taking these
46:17
annotations and finding like kind of the core functions so you know a lot of
46:22
times your uh annotations will involve a description what the gene or what the
46:28
cell does or what the gene does and an onology kind of boils it down to what are the essential categories of those
46:36
things so we can say like if one gene is doing something you know X and another
46:43
Gene is doing y are they two different things or are they part of the same sort of fundamental process or whatever
46:51
so they talk about ontologies they annotate Gene functions without considering by biological context so a
46:58
lot of ontologies and annotations consider function but they don't consider the context of the entire
47:07
genome or the entire cell or the entire organism we contend that the gene
47:13
function problem in genetics may be informed by recent technological leaps and natural language processing so this
47:19
is why they bring up this point about words and sentences sentence context
47:25
because now they're going to use natural language processing which means they're going to use a language model of some
47:30
type it could be like a basic language model it could be a large language model
47:35
that there's a lot of natural language processing research that you could apply to this uh in which representations of
47:42
word semantics can be automatically learned from diverse language contexts
47:47
so you know you're looking at the semantics of a word the meaning and you want to be able to learn this from the
47:53
different contexts of the language how the language is deployed and in biology this is of course means that the gene is
48:01
you know in the cell it's being expressed in different contexts and so when it's expressed in different
48:07
contexts it's doing different things um it's contributing to different processes
48:12
and so we want to be able to develop sort of a biosemantics and of course this idea of biosemantics you know is is
48:20
old it predates The Human Genome Project or any genome sequencing but it's
48:27
something that we can draw from for this uh research as well so in contrast to efforts to model
48:34
semantics as is a relationships so in the 1990s they were using these is a
48:40
relationships which means that uh maybe Gene is a blank and so it's like you
48:46
know has like one function that implies it has one function it implies that it does one thing um that there's no you
48:55
know no contextual variation uh that you know it's like a sort a symbol mean or maybe a word has a single
49:04
meaning or a single symbol associated with it so that's what they're sort of the way that they're modeling semantics
49:11
in the 1990s modern distributional semantics represents words as vectors in
49:17
a learned semantic space so this is where we're in uh I guess in computational linguistics more generally
49:25
today we're using this distributional semantics distributional means that you're drawing from a probability
49:31
distribution and saying that there are different meanings with a different probability and so we can deploy those
49:38
probabilities so if there's a certain if you look at a database of words used in
49:44
different contexts in different books you can see where it's used and how it's used and then you can build it
49:51
probability distribution that says this word is used in this context so much of the time and then you find the the the
49:58
most likely uses of the word in terms of its meaning it's its semantics and then
50:04
you can use that as the answer so that improves over these is a relationships
50:09
and so that's that's a good advance and we want to apply it to gene expression data uh so a lot of the modern
50:18
bioinformatics relies on this older models is a relationship so a lot of the
50:24
um annotations are like this single function or it's just kind of loosely
50:30
describing the function in terms of it's something and so this is a shift in
50:36
terms of how to think about this so uh so you're basically representing words
50:41
as vectors in a learn semantic space and this allows us to use
50:46
Transformer based models like large language models and generative pre-training Transformers so we have
50:53
these tools now with Transformer uh Transformer based tools that would allow
50:59
us to look at these different contexts a similar shift in thinking of Gene functions as distributions over
51:06
cellular contexts so now they're bringing these advances in uh language
51:12
modeling and NLP to uh biology into this problem of Gene functions in different
51:18
cellular contexts and they say it may enable us breakthrough in data driven learning from large biological data sets
51:25
to inform Gene function function so this is really about this question of function and so function is
51:32
interesting because you know to do to do a functional study we have to go back to
51:37
some of the papers we were talking about in the first um in that first uh
51:42
collection of papers that I talked about where you have to observe a a biological
51:48
system you have to assay a gene and sometimes you have an experiment where
51:53
you you know there's a certain model organism there a certain certain way you define the cells and the genes and then
52:00
you look at the function and you say it's doing something because when I make this intervention we're at the stage in
52:07
development there's this effect we can see that that Gene is expressed at a
52:12
high level and so we can make the comparison and say that this is involved in this we can then also do you know
52:20
statistical analysis to show that there's this um relationship between
52:26
this process or this intervention and the expression of the gene but you know we don't necessarily
52:33
know if the gene is always expressed in this way um in this in this relationship
52:40
we don't really have any counterfactuals typically kind of we can run controls
52:45
biologists love controls because it kind of knocks down competing hypotheses but
52:51
that still doesn't solve the problem of context and so if you look at like cells
52:56
in culture you know you'll find that like you're often times doing your
53:02
experiments maybe at a certain point in cell cycle so if the cells are in a
53:07
different phase of cell cycle the genes might respond differently so that's an example of contextual differences so you
53:14
can either run the experiment at different points in cell cycle or you can control for cell cycle or you can
53:20
just simply say that this is you know this result is extremely limited to this
53:26
these specific conditions now that limits our ability to do um uh systems
53:32
biology because we can't say for like the entire range of a system whether
53:39
this result holds so that's really why we're interested in this problem of context and seeing what the functional
53:46
aspect of Gene expressions in different contexts so again they say functionalizing a gene sequence involves
53:54
identifying a biological state in which the gene or protein is expressed and
53:59
experimentally assessing its impact on that state so we you know functionalizing means you have
54:05
identified sort of what the gene is doing relative to the biological process
54:11
and then being able to do that with experiments that can eliminate sort of other explanations competing
54:19
hypotheses and so these discoveries are typically represented as new edges and biological knowledge graphs meaning
54:26
meaning that there connections between two things such that a Gene's function is described in relationship to known
54:32
complexes or biological Pathways so example an example is is a thinking is g
54:39
a is a member of pathway B so we can say that g a because it's doing something in the experiment is a member of pathway B
54:47
but is that true all of the time or some of the time it could be maybe a member of pathway C some of the time and B some
54:54
of the time we can make this statement which is technically true but we don't know how true this statement is how how
55:01
much of the time this this statement is so then that leads us to our sort of probabilistic model where we build a
55:08
distribution of what G is doing how often is it a member of pathway B how
55:15
often is a member of pathway a a pathway C and so forth and it may be that it's a
55:20
member of pathway Vi about half of the time and the other half of the time it's involved either it's quiescent meaning
55:27
it doesn't do anything or it's involved in other Pathways so that's a very
55:32
different answer to the question what does g a do then just simply saying G is
55:37
a member of pathway B because I mean I don't know if if maybe it's involved in
55:43
pathway B all of the time then it's very uh it has like a very high effect on the
55:49
operation of pathway B maybe it has like some influence on pathway B but it's not
55:55
essential so those are very different aspects of what GNA is doing functionally and so they go through a
56:02
lot of things about cell State and how we describe cell State we describe cell
56:07
state in terms of its molecular and biochemical characteristics that change over time and so because it changes over
56:14
time and responds to various stimuli cell State needs to have a better model
56:19
of functions in terms of genes in terms of proteins in terms of anything that's
56:24
involved in sort of maintaining or changing cell state so that's why we're
56:29
interested in the sort of probabilistic model and so this is where they're you know they kind of get into this uh sort
56:37
of existential question for molecular biologists considering these challenges
56:43
what is the best way for molecular biologists to study and represent Gene functions and this has been something
56:48
that's been going on ever since we've been doing studies of Gene function so in searching for an answer to this
56:55
question we found parallels to the study on word semantics in the 1990s summarized in Jord Miller's
57:01
seminal essay to no a word in this perspective taking direct inspiration from Miller we summarize his critique of
57:09
relational models of semantics and describe how transitioning to uh 10 o'
57:15
transitioning to Miller's distributional model of word semantics unlock powerful inductive insights into exploited by
57:23
large language models uh today so they basically want to make this
57:29
parallel between sort of the evolution of natural language processing and the
57:35
evolution of Gene function and to do that they kind of go back to this paper uh by George Miller in 1985 where you
57:43
know they're kind of defining how you know words mean different things in different
57:48
contexts so um I guess you know going through this
57:54
paper you know we we I think this is a nice this is a perspectives article so I don't think there's any real data
58:00
analysis here but it does show you kind of how this works so this figure one is
58:06
um shows the parallels between relational semantics and Rel relational Gene function and so with relational
58:14
semantics what you have are these Isa statements or a series of Isa statements
58:19
so it relates a thing to maybe the things it's related to so for example an
58:26
apple apple is a technology company Apple is also a fruit uh Apple was a
58:33
fruit before it was a technology company but it acquired this meaning when Apple computer started right so it can words
58:41
can acquire new meanings and they can have old meanings that are still very valid now in gene function we also have
58:49
the situation where we have different types of genes sometimes we have genes
58:54
that are sort of ancestral genes we might have a copy that then takes on a
58:59
different function but that ancestral Gene protein relationship is still there
59:06
uh or Gene function relationship is still there and so we have single genes
59:11
like single words that have multiple sort of states of expression or multiple
59:16
meanings so they're drawing upon this distinction but these are just with these is is a statements it's basically
59:24
saying that there's a one toone correspondence between a gene and a function just like
59:29
there's a one toone correspondence between a word and a meaning now that's that's the relational
59:34
semantics model and that's kind of the old way of thinking about this so if you think about this in the distributional
59:41
uh way of thinking about it which is the newer way you actually want to get a distribution of where apple is used in
59:48
sentences in the context so you have a word apple and you have these different
59:53
sentences these six sentences that they pick out and basically it provides different
59:58
contexts for the word Apple so the first one is I mainly use my Apple iPhone to make phone calls so it's clearly
1:00:06
referring to the technology company and one of their products and doing something active with
1:00:12
it uh this one here is I picked a red apple from the tree in the backyard this
1:00:17
is of course the fruit but it's also doing something on that apples grow on trees whereas with the technology
1:00:24
company they make phones that you can call people and so it gives you information when it's embedded in that
1:00:30
sentence and so then you have this this PO semi graph here which means that you
1:00:36
start with apple and there are these vectors that radiate out from a common Point uh Apple being the term that
1:00:42
you're interested in and there are these other things associated with it in different locations in this PO semi
1:00:49
space so you have computer phone Orchard SE and tree those things are all related
1:00:56
to Apple they're in different uh directions in this ho semispace but
1:01:01
they're all related in terms of meaning uh in this case with Gene plot
1:01:06
tropy you have this data set where you have uh different genes and different
1:01:11
cell models so models of the cell different contexts you can then look at these genes as they're expressed in
1:01:18
these different contexts and you can draw relational statements between them you can say that Shock 2 is related uh
1:01:26
in terms of expression to map K7 kras docs vja 7 nraas and RAF one they're in
1:01:35
different directions again like these other words but they're related because they're now this isn't a sentence but
1:01:41
this is a sequence of sort of gene expression that cooccurs within a
1:01:47
certain cell model so if you look at like for example Shop 2 it's coexpressed with rafh one in cell
1:01:56
model 10 it's also coexpressed with crass map Cas 7 and Doc 5 ggia 7 and
1:02:03
nraas are not involved in that cell model just as some of these meanings are not involved in every sentence in the
1:02:09
distributional hypothesis of word meanings so you have this parallel between how sentences give you know
1:02:16
context some things are related in some sentences some things are related in other sentences with this you know H
1:02:23
distributional hypothesis of Gene function or different cell models Express certain genes but if you go across all the cell
1:02:30
models and these cell models could be like different model organisms different types of cells there's this space that
1:02:38
you can characterize where all these cells are involved at some level they're they're they kind of group together or
1:02:44
they're related but they you know in some models they're related and some they aren't so you can build this kind
1:02:50
of distributional uh data set and then you can look at the way they're distributed
1:02:56
to get answers about their function and so this is again you know
1:03:02
we've talked about using large language models in the context of looking at uh
1:03:08
Gene sequences proteins and predicting protein sequences but here we're
1:03:13
actually trying to predict function so we're moving up maybe one level and saying this is not just the sequence
1:03:19
this is the function and so this is um you know there there's a case to be made
1:03:24
here I think it's maybe a little bit less clear than what's going on with like uh DNA sequences or protein
1:03:31
sequences but still I think those these word semantics they have they they can be informative of Gene function so you
1:03:39
know they give a couple of points in support of this first there is an apparent organizational hierarchy both
1:03:45
in linguistics the morphology of language and biology we know from geneontology that there's this
1:03:51
organizational hierarchy of uh Gene function uh definitions uh where the combination of
1:03:58
fundamental lower level elements give rise to emergent higher level
1:04:03
entities um the second point is that both words
1:04:09
and genes are susceptible to analogous Dynamic changes in Fitness over time uh
1:04:15
further recog recognition of the evolvable characteristics of words meaning that words change over time they
1:04:21
change their meaning like we've discussed that they can mean different things at different different points in time they can be associated with
1:04:28
different things at different points in time and so it is with genes and their
1:04:33
functions um linguists have developed taxonomical methods of tracing the ordinance of words through philogenetic
1:04:40
methods so Linguistics uses phog gentic methods and lo and behold biology also
1:04:46
uses philogenetic methods so it's very compatible in that sense third both genes and words are
1:04:52
amenable to study the perations so again you can run these experiments where you can perturb the system you can actually
1:04:59
do this also in linguistics and psychol Linguistics in particular where you can
1:05:05
change words the meaning of words you can modify things at a sort of a
1:05:10
singular level at the level of like the symbol so it's it's you know there are a lot of things we can learn from say
1:05:17
Linguistics and language modeling natural language processing we can apply directly to you know gene or or
1:05:24
biological sequences and maybe even Gene function uh and then fourth there has
1:05:31
been an astronomical increase in data availability both linguistic and biological so we have a lot of data
1:05:38
biological data we can use for this we can use Gene sequences indeed but we can also use other types of expression data
1:05:45
which aren't sequential in this in the conventional sense but we can build sequences of uh you know distributional
1:05:53
sequences of expression by looking at like a set of genes that are expressed in a tissue or you know a set of
1:05:59
conditions where different sequences are expressed we have RNA seek data where
1:06:05
different uh fragments of of RNA are associated with an expression value and
1:06:10
we can use those to sort of say things about you know maybe not even about genes just about sequences that we can
1:06:16
map to a specific Gene in a genome sequence and so we can do a lot of
1:06:22
interesting things this is a vision paper again so they don't really show like any sort of really good analysis
1:06:30
but they give a lot of food for thought here and so finally genetics may have
1:06:35
much to gain from uh shifting from relational to distributional representations as semantics did
1:06:41
throughout the 2010s Miller's changing of modeling polysemic words in the 1990s
1:06:46
was later solved with distributional semantic models such as word toac so word toac is a classic Model in language
1:06:54
modeling where sort of a abled large language models uh but you know we have
1:06:59
these kind of these tools that exist in language modeling that we can use for
1:07:05
biology correspondingly we and others have found that applying similar methods also recover orthogonal Gene functions
1:07:12
when applied to genome scale Fitness grades this is a good good article thank you for the find on that Morgan all
1:07:21
right uh yeah stuff thank you for going over that but I missed I missed the
1:07:27
thorax part oh yeah all
1:07:33
right all right well that's great so thank you for attending and if we don't
1:07:39
have any other comments or questions we call it a
1:07:45
meeting all right thanks see you next week okay bye bye now I'd like to
1:07:52
introduce a resource that we talked about last week and last week's meeting also is relevant to the data sets we
1:07:58
talked about this so this is the seigan interactive cell engage this is by Nick Hill POA
1:08:05
based on worm web or it's hosted on worm web and so this is a nice resource for
1:08:11
looking at developmental lineage trees and sea El so this was put together from
1:08:17
existing data there a lot of data sets in the cgans community that we can use
1:08:22
we talked of course about solon's work at 1977 where he laid out the lineage tree
1:08:29
drew it out by hand and so all of this is based on that those data but other
1:08:35
data as well about the timing of Divisions and some other materials as
1:08:40
well so this is starting at the Single Cell of zygo which is referred to as P0
1:08:45
this is the egg that gets fertilized and because a most the elegans are
1:08:51
hermaphrodites this happens on the same worm so they fertilize the eggs becomes
1:08:57
the zygote that's a single cell that zygote then divides into two cells AB M
1:09:04
P1 and that establishes this uh anterior posterior uh polarity and then you have
1:09:13
the division of cells in the ab lineage and division of cells in the P1 lineage
1:09:19
and so you can see that you have this representation you have this uh time scale in minutes so we start with the
1:09:26
two cell stated minute zero and we go down so all the cell tracking data that
1:09:32
we have uses the same convention ab and P1 are times zero because the division
1:09:39
event first division event happens when those two cells are born now in terms of the
1:09:45
terminology p 0 technically is the parent of both ab and P1 and thus is the
1:09:52
parent of the entire lineage stream AB is the parent of ABA and
1:09:58
ABP and th is the parent of the entire AB lineage and the interior end of the
1:10:04
worm or the head uh so that's the uh nomenclature
1:10:10
there it's it's important to point out that you also have these things called founder cells and the founder cells are
1:10:17
the parents of a specific suin AG so this whole lineage tree has a number of sublineages it has the ab sublineages
1:10:25
here here it has the E sublineage the MS sublineage the C
1:10:31
sublineage and then this P which is goes down to the germ line so if you expand
1:10:36
out P3 you end up with these Z cells and these Z cells are the germ line which is
1:10:43
separate from the rest of the worm that goes on to create the sperm and the eggs and the things that are involved in
1:10:51
reproduction uh there's also d as a Founder cell that founds the lineage and
1:10:56
so we have these founder cells which are sort of at the top of a certain set of cells uh some cells are specialized for
1:11:04
like gut or muscle some cells are more General like in thead lineage we have a
1:11:11
number of cells uh epithelial cells neural cells and so forth so the fates
1:11:16
vary more widely in the ab sublineage and some of these other sublineages the posterior end they're very specific like
1:11:23
the germline or they have spec more specific functions like the C and D
1:11:32
Subs so as you can tell what you have is this visualization of these data that
1:11:38
are exist in the public domain one of the things I like about this
1:11:43
resource is that you have all the information about a cell sort of in the Le hand side so you can check your work
1:11:50
uh so you have the birth time you have information about the death time now C
1:11:55
does not die it divides into daughter cells so it doesn't die it just transforms into a two cell type so C
1:12:03
persists which is a better term from the beginning of C to the birth of CA and CP
1:12:09
so C starts at 42 minutes CA is then one 70 minutes and so C persists from 42
1:12:16
minutes to 70 minutes and so if we'll look we're building a representation of this you know that's how we would Define
1:12:25
that cell C is existing from a division of P2 which divides into C P3 so P2
1:12:35
persists from 18 minutes to 42 minutes C
1:12:41
processed from 42 minutes to 70 minutes so that's how we would build our
1:12:48
representation then as time goes on as you can see cells proliferates so we have we can unfold this
1:12:55
line sublineage and it unfolds a couple of layers you can see the divisions that
1:13:00
occur u in in C sublineage also in D sublineage we can expand that out as
1:13:08
well and with d sublineage we can start to see uh some
1:13:14
differentiation so in D we have these cells that these what we call
1:13:19
developmental cells so we go from D to Da the daa and dap
1:13:26
daap and daaa and again these letters that uh are appended to the sublineage
1:13:34
identifier describe anatomical orientation that these cells take so the
1:13:40
D sublineage goes anteriorly and posteriorly to the original D
1:13:45
cell uh this daa is three divisions anterior so when a cell divides the cell
1:13:52
either divides in the anterior or posterior Direction daaa is three
1:13:58
anterior divisions in that direction and at that point we have daa which is born
1:14:04
at 210 minutes and it divides into two daughters but those daughters are no longer developmental cells they divide
1:14:12
into what we even look over on the uh Legend we have muot and muot so they
1:14:19
have the same name but it's no longer that developmental nomenclature these are differentiated so if we click on mu
1:14:25
God we get information it technically has a developmental uh nomenclature name
1:14:31
but it's actually now differentiated it's actually muscle and so we can say
1:14:37
that this muscle cell is uh 275 minutes
1:14:43
this muscle cell is born at 275 minutes this muscle cell from daap is born at
1:14:48
278 minutes and so forth so we can see
1:14:55
that at around this time of 270 to 280 minutes we're starting to get these uh
1:15:02
muscle cells and mu B basically the body wall the work so we're starting to get
1:15:08
parts of these uh the anatomy being formed at that stage in elopment and so
1:15:15
as you can see from this uh tree that not all cells differentiate at the same rate so you
1:15:22
get more of these mubod cells here at 265 minutes you're starting to assemble
1:15:29
these tissues at around this time but there other tissues that form later this
1:15:34
this is a very early tissue that gets differentiated you see that there's more
1:15:39
of this in the sea lineage and so
1:15:46
forth so if we move over to the ab1 we've ignored that for a while we see
1:15:51
that these developmental cells go down quite a way days in fact we have
1:15:56
developmental cell divisions down to 280 minutes at the same time we have body
1:16:02
wall muscle forming in these sublineages in the posterior end we still have these
1:16:08
developmental divisions in the anterior and what we have here is we
1:16:14
have
1:16:22
uh so what we have here is an example of an asymmetric division so we have these
1:16:28
uh divisions and we have like actually I think six or seven division events
1:16:33
anterior a left division and anterior anterior a left so they move anteriorly
1:16:39
posteriorly but they also move left and right as well so you can see lnr in the ab sub lineage so they can move left and
1:16:46
right anterior posterior these two dimensions of the embryo uh but also at
1:16:52
some point you start to get differentiation and as we saw with body muscle body wall muscle you have these divides into two
1:16:59
cells and then you know you get two two
1:17:05
anatomically mature cells differentiated cells uh in this case we have one
1:17:12
anatomically mature cell so we get here as neuron in a
1:17:17
inl and it has a again a lineal name it's born at 325 minutes but it sister
1:17:23
doesn't live but sister actually doesn't live it's actually cell death it's what
1:17:29
we call program cell death or eposis and they have this little symbol
1:17:34
of death here just to let you know that this is dead and it's not going to different it's not going to exist
1:17:40
anymore in the anatomy as opposed to a NL which will exist throughout adulthood
1:17:46
it's this neuron that's defined in connecto and so we see the same here I
1:17:52
shl which is the uh a sheath cell which is actually part of the connectone as well it's a
1:18:00
sheath you have this cell here IL shl which is a sheath cell and this is more
1:18:06
than 317 minutes but again it's sister apotosis and doesn't exist anymore so
1:18:13
this is an example asymmetric division where you have one daughter but not the other surv
1:18:42
so again uh you get these sort of asymmetric cell divisions where you have
1:18:48
an appos daughter and a daughter that goes on to four so differentiated cell
1:18:53
you also get the uh symmetrical divisions where you get two uh differentiated cells and that's
1:19:01
true throughout the tree you'll see examples of both of these and so we can actually find the time when these
1:19:08
divisions occur we can find the names of the cells we can know what Fates they're going to become or if they're going to
1:19:15
apose uh and not become anything and so we have all this information in this interactive tree and encourage you to
1:19:21
look this interactive tree over if you're doing work at the data sets to verify things thank you and I hope you
