     
Transcript     
0:07     
hi hi you can hear me yes okay good     
0:14     
okay all right so hello mahul how are     
0:21     
you hi Bradley hi everyone hi Susan hi J     
0:27     
hi uh I'm actually at my uncle Place uh there's an Indian festival so for that     
0:33     
I'll actually switch off my camera okay and I have yeah I have a few updates to share uh actually it is more on the     
0:40     
notes format I put it on paper and I'm in the process of writing code uh and I     
0:45     
wanted some inputs Also regarding that uh can I share my screen yes go ahead     
0:52     
yeah okay thank you there is yeah I found     
0:57     
it screen     
1:03     
okay yeah I hope my screen is visible yes okay yeah so uh I was so last time     
1:10     
we were in the process of what we have done is we have built the hypergraph uh for a normal uh data like let's say     
1:18     
which is not temp not considering the temporal aspect of it so for that we we     
1:24     
have the ideation of two concepts like first is the distance based hyper graph and the second is uh based on uh their     
1:31     
common parent so I was actually exploring and yeah and the second thing which we did was uh make the hyper graph     
1:38     
which is temporal so for let's say every 10th time Point uh we are going to make a hyper graph so we have till 190 points     
1:45     
right in the data set we are using so we can make a hypergraph even for all the data points but for visualization we saw     
1:51     
last time that we had hypergraphs for every for every 10th uh time uh time     
1:56     
sequence so now after that the question question was what metrics we should use     
2:02     
to basically say about different nodes or hyper nodes so that is where I was     
2:07     
exploring the literature I was like pretty confused type what metric should be use so that's where I made some notes     
2:14     
so I have I'm I'm trying to implement this like in a proper like good format coding it but it's not complete yet so I     
2:20     
thought it's better to explain it through notes rather than going to the code uh so I'll just go through it so     
2:27     
explaining what a simple hypergraph is so it can be it can be understood by three main metrics which is v e and I so     
2:34     
V is the set of nodes uh or we can say hyper nodes hyper nodes are like AB a     
2:39     
all the cells during abis and the second is uh we have like sets of edges so or we can say as     
2:46     
hyperedges also right so interactions of these hyperedges can be based on either as we mentioned like either based on the     
2:52     
similarity uh distance metric not similarity uh or or the other thing can     
2:58     
be based on like common parent so let's say if yeah so for examp one example can     
3:04     
be uh AB is the mother of ab a and let's say also AB d i can I may use some wrong     
3:11     
names but let's say AB has like two uh daughters so now we will have two nodes     
3:17     
or two hyper nodes uh in uh which are ABA and ab ab B but we are going we are     
3:25     
also going to name the hyper Edge so the hyper is going to be the uh the parent the mother so that will be AB so that     
3:32     
was an instance where how we can represent what we can represent through edges uh yeah and third is basically I     
3:40     
which we call as incidence Matrix which basically tells what are the connections between uh nodes and Hypes so it can be     
3:47     
presented as e andv uh my bad sorry for the handwriting I'll try to explain every part if it's not clear we can go     
3:53     
to it again yeah so initially we were considering only like zero and one connections either connection or either     
4:00     
we don't but it can be extrapolated to other things I can we can explain we can     
4:06     
we can think about it later uh but essentially we are going to have hyper hyper matri hyper uh incidence Matrix of     
4:13     
hyper graph which will be of Dimension V cross e so e v is basically of nodes and     
4:18     
we are like and as I like said it can be weighted or it can be like unweighted     
4:24     
right um yeah so yeah so this is like what I I     
4:29     
explained before now coming to second part uh so what I was uh so one     
4:35     
definition I read about multi hypergraph actually so and I think that is what we are going towards in the end so what     
4:43     
hyper graph what multi hypergraph says by like proper definition is it allows     
4:48     
distinct edges to contain same set of nodes so what it so like different     
4:53     
distinct edges what I mean by that is so one Edge can represent the distance and the other Edge can represent the     
5:00     
the her how which cell is the parent of that so since we combine these two     
5:06     
different kind of hyper edges uh we have the we have the multi hyper and there     
5:11     
can be situations in which there are two hyper edges which are like different types as been mentioned and they have     
5:17     
exact same number of elements so that is what by definition we say it's and then yeah so and then coming to     
5:25     
hyper nodes so I was uh reading few literature and also the libraries just     
5:31     
to so we have discussed the definition of hypernotes but I wanted to still clear more on that so that is what     
5:38     
actually literature says hypernodes is used very Loosely in different situations but I try to formalize it in     
5:45     
our case so hypernotes can be defined by three important or four important parts     
5:50     
so one is the unique identifier that we have a unique label for every hyper I'll     
5:57     
give an example later on and second is we can have metadata for it so metadata can contain like distance the XYZ     
6:03     
coordinates and also like the uh the size of the cell right so it will have that and it can have an Associated     
6:10     
weight so weight can be anything it can be weight or something else and of course the membership which every hyper node has so in our example what uh what     
6:18     
is the difference in hyper node and node so we can consider first let's go to node right so node can be let's say a     
6:24     
single cell which is AB so AB can be uh at different places right so AB uh can     
6:31     
originate at different time points and different different places so collectively we call it as nodes but     
6:36     
hypergraph is more specific when when we say hypergraph we have to we have to Define its specific time point which it     
6:43     
which it exists and also the metadata like the coordinates right so if we are talking about specific then we say     
6:50     
hypernotes otherwise for General we are going to use let's say AB as its high     
6:55     
node so that is like I think a good distinction to uh Define what hyper     
7:00     
nodes in our case is going to be yeah okay and then uh yeah and then     
7:08     
there are few metrics I think which can be very useful to us so one is like s adjacent so what ad s adjacent says is     
7:15     
so let's say we have two nodes any two nodes or any two cells if they belong to a hyper Edge uh then that hyper Edge     
7:23     
should have like at least a number of I'm sorry have at least s number of cells and that is uh and that is is the     
7:29     
only way we can say that uh those two nodes are as adjacent um let me know if     
7:35     
I don't Define it properly I miss out yeah I not explain it well yeah and the     
7:41     
second is s adjacency Matrix so adjacency Matrix is defined through the S adjacent metric only uh so if let's     
7:48     
say two nodes are uh are belonging to uh one hyper Edge which has a size of s as     
7:56     
I mentioned then we will have one across this this SED Symmetry and similarly for     
8:01     
all all the nodes and also we can extrapolate it to weighted hyperedge so if let's say those particular two nodes     
8:08     
belong to like more number of uh such hyper edges which are like s adjacent so     
8:14     
then we can have like Ved version of this and I think can be useful uh to represent relations of of two nodes uh     
8:23     
uh not in the form of incident metrix like we were sh in the hypergraph but deriving the adjacency metrix from the     
8:29     
incident Matrix itself uh from the hyper graph essentially so this is one concept     
8:34     
uh and the second is I think     
8:40     
I yeah so I think I'm trying to Define     
8:47     
why okay so the next is uh the S auxiliary Matrix so I'll just Define it     
8:53     
then I tell what is the usefulness of it so s auxilary Matrix is like uh so there     
9:00     
are going to be some so in the previous uh yeah so in the previous defination of     
9:07     
adjacent s s adjacent we defined as s adjacent metrix right so we are going to have a lot of zero values it's not going     
9:14     
to be like completely one one or completely it's going to be quite sparse right so for for reducing the sparsity     
9:21     
what we do is we create this as auxilary Matrix so whichever rows or whichever columns which are like completely zeros     
9:28     
we just remove those uh rows and columns so what we will have in the end is we will have only few cells which have like     
9:35     
strong connections between them why strong because strong the strength will be defined by what s we choose if we     
9:41     
choose a higher Edge if we if we choose a higher s value then we are going to have more sparity in the S adjacency     
9:48     
Matrix and hence a smaller s auxilary Matrix so uh previously we were seeing     
9:54     
hyper GRS which were quite dense right uh even the interactions which are not very important were also coming that     
10:01     
so if yeah if we construct s auxilary metrics hold     
10:08     
on yeah sure all right go ahead okay yeah so if     
10:19     
we construct instead of the complete hypergraph if we construct the cond condence version of this which is the     
10:25     
auxiliary one then we are going to see more clear and more important connections other than seeing all kind     
10:31     
of connections so I think this can be little more useful actually very more     
10:36     
useful compared to what we were seeing the previous uh big big di like very dense diagrams right and then yeah and     
10:45     
then yeah so this is about like nodes now second concept is the second topic is about like the Dual of hypergraph so     
10:52     
we discussed it little bit like what do all mean so let's say if we if we exchange the nodes with the edges     
10:59     
becomes the nodes of the hyper becomes the edges and the edges becomes the no I     
11:05     
mean like it's quite complex to think but uh it can be understood in a way that we were we made a hypergraph of     
11:12     
this uh this hierarchy right in which like uh the the the parent was the hyper     
11:17     
and the and the children were the no so like if you let's say exchange a definition like uh that the parents     
11:24     
becomes the nodes now and uh yeah and the children become the hyper edges so     
11:30     
this that will be the Dual of hyper graph so similarly for this dual of the hyper graph we can Define this as     
11:37     
adjacency so previously we call it s adjacency now we call it s Edge adjacency so it will have like similar     
11:43     
definitions but it will be more focused on uh the parents uh instead of the children in the hyper graphs and from     
11:51     
this definition we are going to have like s adjacency uh Matrix uh s Edge     
11:57     
adcy Matrix and and yeah similarly we are going to have auxilary Matrix as     
12:03     
well and I'm yet to complete more on this matrics and yeah so I'll explain     
12:10     
the next two along with that connected to those yeah so that's all uh yeah that's     
12:17     
all for the uh updates uh but any questions or any feedback on this the     
12:24     
last two here are s connected and S Walk So what are those     
12:32     
yeah um actually uh so for this I think we     
12:39     
need to Define certain more terms so for S connected uh we need to Define s and     
12:44     
for S I have to Define like certain more uh metrics so I'm actually not very sure     
12:51     
what s is so that's why I didn't mention it right now okay so I'll yeah I'll try     
12:57     
to cover it next time the concept is basically that you're walk going across the graph it's kind of     
13:04     
like a random walk but it's not because it's a hyper graph it's a little bit     
13:11     
different is that correct like     
13:17     
yeah right I think you yeah you're very correctly mentioning it like it's like a sequence of not like we got on a path of     
13:25     
a work off nodes uh but we don't uh like as you said in the hypergraph uh it's     
13:30     
little complex and also we threshold the work based on like this value of s so     
13:36     
it's like uh if two nodes uh have like if two nodes belong to a hyper Edge and     
13:43     
that hyper Edge has at least s number of nodes then only uh we are going to walk     
13:50     
through that like pair of nodes and later on as like sequence of I am not     
13:56     
very sure how it is useful and not very sure also what exactly it means uh in     
14:01     
the case of hyper graph so yeah I I'll try to have more clarity     
14:07     
and then I'll come back on this okay that's that's great uh thank     
14:13     
you Mah for the update are there any questions uh that we have for     
14:23     
mul yeah Bradley yeah Gordon yeah uh     
14:29     
this is very similar to something I'm doing in computer tomography uh and I bring up the     
14:36     
analogy uh there's a new technology which allows one to aim an x-ray     
14:43     
beam okay so a narrow x-ray would be a line across the tissue that you're     
14:52     
trying to image okay yeah now if we consider a     
14:57     
number of lines which can cross one another then we can attempt to     
15:03     
reconstruct an image by using an infilling algorithm between the lines where the     
15:10     
lines are first run through a computer tomography algorithm yeah okay so the     
15:17     
x-rays can be regarded as a graph uh which is a little strange     
15:24     
because the entrance and exit makes the graph have     
15:30     
have line segments that stick out from the graph okay so that's the only the only     
15:36     
difference from a a standard graph yeah now we can pull the same     
15:42     
trick uh each line of an x-ray can be     
15:48     
regarded as an edge and the intersections as nodes yeah but then we     
15:54     
can also make the Dual graph which where each line becomes a node and the uh     
16:03     
edges become connect become overlaps between     
16:08     
lines so if you if you have a given line it     
16:14     
intersects some set of other lines and those lines intersect another set of     
16:19     
lines Etc until you cover the whole thing yeah okay     
16:25     
now we're considering dra computer demography just well consider the     
16:32     
distance consider a given line and then     
16:37     
consider the distance of that line from other lines in terms of how far on the     
16:44     
Dual graph you have to go out to get to those other lines this this gives you a     
16:50     
set of sub graphs which are based on the duel uh which go further and further     
17:00     
away from the initial line that you started with now we're doing a     
17:05     
calculation on each line which is a computer tomography calculation and I'm     
17:11     
speculating based on what I called the locality of computer     
17:17     
tomography uh which means that if you change a given region it doesn't seem to     
17:22     
affect other regions very much so I'm generalizing that to the     
17:27     
Dual graph and what you do is do the computer tomography algorithm just on a line and     
17:35     
then the neighbors of the line and Etc so you can go out let's say you got n     
17:42     
lines you can go out to I lines where I is less than n right okay so you're sort of spreading     
17:50     
out in the Dual graph the the point is the reason for     
17:56     
doing that is that the computer tomography can get worse and worse as you increase     
18:02     
the number of lines uh so by stopping at a uh at a     
18:08     
certain distance for a given line in terms of the Dual graph uh you could speed up the     
18:14     
computation and under the assumption that of a locality generalizing to dual     
18:20     
graph uh it should converge fairly rapidly uh you don't so you don't have to do all the     
18:27     
lines Okay so it's very of similar to this uh in using little of the     
18:33     
graph and the analogy might make uh I don't know how popular this is in India     
18:39     
but uh uh the kids game of Pickup Sticks can be regarded as sticks are adjacent     
18:47     
to sticks that overlap them and then those sticks are adjacent to uh sticks that overlap those so so pickup sck sort     
18:56     
of gives you a an analys where you can get the dual of the pickup     
19:01     
pickup sticks uh so you can you can visualize this in     
19:07     
uh by just throwing a bunch of Pickup Sticks on top of each other right okay     
19:12     
so that that's where we're going with this it's a new kind of computer to algorithm which works on graphs and on     
19:19     
the Dual of the graph and that's where we're at right now we     
19:25     
we're uh I'm working with uh uh within on trying to implement     
19:31     
this yeah but it looks very similar in structure up yeah yeah I think it it you     
19:40     
know you could represent that as a graph and and kind of find a shortcut no pun intended to uh so you know to sort of     
19:47     
speed up the algorithm you just characterize those set of points and     
19:52     
then characterize another set of points and so forth yeah     
20:01     
yeah and then the aim of that is to uh to increase the dose by adding one more     
20:08     
line and you uh we have to come up with algorithms for how to choose where that should be which is image     
20:16     
dependent okay because we're trying to locate tumors uh in breast     
20:22     
ti so uh that's where we're at that's where we're at uh we have haven't got an     
20:29     
algorithm yet for how to add the next line so the graph keep keeps getting     
20:35     
more and more complicated by adding lines which corespond to     
20:41     
x-rays uh and uh but you add them in an image dependent fashion and the question     
20:47     
is whether this whole thing is going to converge uh and whether it can be done with reasonable Computing time right     
20:56     
right yeah that's yeah that's great it's kind of strange     
21:02     
to doing computer tomography on The Duel of a     
21:07     
graph yeah yeah okay that sounds very interesting uh     
21:14     
yeah that's where we're at right now trying to set this     
21:20     
up yeah so so do actually like uh I     
21:26     
really like uh how you like you probably can utilize dual of a graph but uh is it     
21:33     
possible so now uh like in dual you would be exchanging the roles of edges     
21:38     
and nodes right so is there any attribute yeah sorry any     
21:45     
what you're probably like exchanging the roles of Edge and node since we want to     
21:51     
focus more on edges yeah so are edges like very clearly defined in terms of     
21:58     
like teral ology like our Cas we're doing it in two dimensions for     
22:04     
now so the question is just are two lines cross do they cross within the     
22:12     
tissue okay because we're dealing with a finite region uh you know two     
22:19     
lines two lines that are not parallel in general will cross but we need them to cross within the tissue and then they     
22:26     
form the graph uh okay okay makes sense yeah makes     
22:35     
sense so uh so yeah go ahead sorry please go on yeah     
22:41     
so what I was asking is like uh so is there any terminology associated with every like connection between the     
22:47     
tissues which you're talking about so for every connection do we have like some names given the formal ones uh only     
22:54     
we're adding one line at a time uhhuh so you can number them     
23:01     
consecutively but that's that's all but the the one you     
23:06     
add has to be one which improves the image as best as possible and that we     
23:12     
haven't got we haven't figured that out yet because what you're doing is have     
23:17     
all these lines crossing and you're using an inpainting algorithm to fill in the space between     
23:22     
them so you get an image and uh the question is does the image show tumors or not if if it's     
23:30     
seems to be showing tumors then in some fashion you you pick the next line to go     
23:38     
through the supposed tumor and the uh the result should be that either it     
23:44     
sharpens up the image of the tumor or was a noise fluctuation and the supposed     
23:51     
tumor disappears you stop either you stop     
23:58     
adding lines either when you found tumors uh or you've uh reached the     
24:05     
maximum lavable dose which is proportional to the number of     
24:11     
lines okay yeah so there's a stopping procedure but what's unusual about this     
24:18     
is that in computer tomography you normally consider either     
24:24     
a fan beam of x-rays or a colon Beam for three dimension in that case you're splattering your     
24:31     
x-rays over normal tissue and the tumors Trying to minimize the dose to     
24:38     
the tumors to normal tissue and maximize the dose     
24:44     
to to possible tumors so that's why the addition of the     
24:52     
lines uh is image dependent and uh the aim is to keep the dose as low as     
24:57     
possible ah okay okay okay that sounds very     
25:04     
interesting uh thanks for giving the information okay     
25:10     
sure yes okay well I I missed the beginning of this uh what's the context     
25:16     
of your gra I'm sorry I missed it out what is     
25:21     
the context yeah what is the context of your build building these sparse     
25:26     
graphs uh uh uh so like uh like previously uh when I presented what we     
25:33     
had was our uh so the hyper graph which we constructed uh if we if we include     
25:39     
all the time points also it became very complex or let's say if you make a dynamic graph in the initial time points     
25:46     
uh it was sort of like very clear but we as but as we go to like time point at 150 it becames very very D to observe     
25:53     
the important interactions so uh if we like talk of auxil Matrix uh     
25:59     
I want to uh like uh basically observe only the     
26:05     
interactions which are important for us not like the complete hyper graph and yeah but talking about the importance of     
26:11     
dual dual of a hyper graph uh uh so when we like like when we are focusing on     
26:18     
just the hyper graph when we have the hyper graph of let's say the hierarchical parent like parent uh child     
26:26     
uh interactions that hyper was capturing the interaction between the children that these children are of a common     
26:32     
parent and that's what we were observing but I also thought like observing the     
26:38     
interaction of the mother could also be important so that's why I started focusing on Dual of hypergraph because     
26:44     
mother is representing is by the hyper edges yeah so that was like my motive     
26:51     
yeah in in our case what we're trying to do is get a subgraph from The Duel where     
26:57     
the subgraph uh distance where distance uh is counted in the uh oh how     
27:06     
should I say how many nodes you have to go through to get to a given     
27:15     
line in other words if you have if the if if an xray is crossed by other     
27:23     
x-rays then you consider those x-rays that that uh cross it and then you     
27:29     
consider the x-rays across those so at each step you can call you can talk about a distance in the Dual graph how     
27:36     
many how many edges of the Dual you have to go through to get to a given uh to a given     
27:44     
X-ray and uh uh the idea is to minimize the computation in other words minimize     
27:51     
the graph by uh minimizing by by using a a given number     
27:58     
of steps going from a given line to the other lines or in this case given no to     
28:04     
the other lines indidual okay okay that's interesting     
28:10     
but I didn't understand this properly I'll probably watch the yeah the recording of it again yeah I have some     
28:17     
questions but I'll try to reach out to you if I like if I'm not able to clear them in the next meeting let me I'll put     
28:23     
my I'll put my uh email address in the chat okay sure     
28:30     
yeah okay there you go yeah thank you very much all     
28:36     
right uh yeah I wasn't expecting to see this convergence of ideas yeah     
28:45     
yeah uh so I had a couple questions mahul about the notes yeah so first of     
28:52     
all yeah I think this is an interesting idea like what Dick's talking about is putting line through tissue like they're     
28:59     
Imaging a tissue volume and then they're putting lines through it as like x-rays     
29:05     
but you can think of those lines is kind of like hypothetical lines through some geometry like if we took celegans for     
29:12     
example we could take lines through and predict the centroids of cells or     
29:17     
different features in the cells and so you know this is just kind of a blind approach to like kind of segmenting     
29:23     
images where you put a line through and you see what's on the line and then you know you build a network from that so     
29:30     
like say we weren't trying to uh use cells or the cell centroids say we were     
29:36     
trying to use like different uh organel or different you know protein Gomer or     
29:43     
whatever and we wanted to kind of characterize a network of those but we only had our images and we didn't really     
29:49     
have a good way to quantify the position of those um well     
29:54     
we we knew them in the context of the tissue so we could actually do something like this to find sort of the     
30:00     
intersections of these protein aerations and build a set of lines or a     
30:06     
set of edges that then kind of tell us where the nodes are because the lines are kind of     
30:11     
connected and you know it's a little bit kind of hard to maybe understand what I just said because you're thinking about     
30:19     
like this it's it's a little hard to kind of wrap your head around but like let's say we just wanted to like survey     
30:25     
a set of lines through the tissue it's kind of like when they do um geology and     
30:31     
they do transects through like some place they want to like sample and dig     
30:36     
and find things underneath the ground um you know you're just kind of you know     
30:41     
developing a sampling strategy so you just set up put a set of lines across the tissue across the images and see     
30:49     
what's there and then when there's like an intersection you count that as a node     
30:54     
and then it's almost like an exercise in geometry because then you like say basically you     
31:00     
know what is that those intersections how do they relate to the geometry of the worm or the tissue and you know we     
31:07     
can we can do things like that so I think it's an interesting approach also for Imaging     
31:12     
stuff um yeah yeah Bradley there's also     
31:17     
the the the how should I say uncertain observation that cells can     
31:26     
have an effect on cells at some distance from them right signaling yeah okay and     
31:33     
uh and so the that dual graph can give you an idea of how far cells are apart     
31:42     
in terms of H uh signaling or something uh yeah I just read a     
31:48     
fascinating paper where some bacteria they actually form a line of cells that     
31:53     
gets quite long and can signal along the line by an electric current     
31:59     
yeah okay now I don't know what the bacteria do with that     
32:05     
but well yeah they probably form like an antenna     
32:12     
right yes they're they're in connection connected to aliens Yeah well yeah I     
32:19     
mean sensing the environment they have to do like Collective sensing they have to get a yeah it could be could be and     
32:26     
the idea that cells interact with at a distance is already established in bacteria right yeah yeah there's a lot     
32:34     
of interesting stuff in bacteria but like environmental sensing because they're they're kind of like they form     
32:40     
these colonies and they have to kind of figure out what's going on out at Scales larger than just their immediate     
32:46     
space and so that's that's something in seans too there's the the interactome and seans and people have been working     
32:54     
on this where they say you know cells of course um have different chemical signals that     
32:59     
they send out and receive from other cells so if there's like some you know injury to the uh tissue there's some     
33:07     
signal that's sent out or there's some migratory signal that's chemical and     
33:12     
it's like you know a way to get the cells to sort of coordinate their activity and move in a certain way so     
33:18     
for wound healing for example you get this sort of coordination where cells are M migrate to the site of injury and     
33:24     
then you know um cover up eventually grow over the sight of injury yeah yeah     
33:31     
you also have this discordance with all of Michael Len's were which which tends     
33:38     
to show long range electrical activity in embryos yeah and wound healing is also     
33:47     
very sensitive to Electric currs right okay so uh uh the long the range r     
33:57     
be worthwhile characterizing yeah yeah there's a lot of work actually     
34:04     
yeah and like uh they call it well they have endocrine signaling and paracrine     
34:09     
signaling paracrine signaling being shorter range stuff and endocrine signaling being longer range stuff so     
34:16     
there's a literature on this those are assumed to be chemical based I'm saying yeah electrical phenomena may also be     
34:23     
worth considering right oh yeah yeah     
34:30     
okay yeah okay so M very fascinating yeah     
34:35     
yeah thanks Mo for thanks and yeah and actually I     
34:42     
understood the analogy you gave was very useful and I got the intuition of it but     
34:47     
I'll try to wrap my head around like by thinking more about and like I'll watch     
34:52     
the recording again the specific Parts you said in the beginning so yeah than but thanks for the input oh no crap     
34:59     
So yeah thank uh thank you mahul for the uh poll request that you uh made earlier     
35:04     
this week I accepted it and it's it's in the repository um so what are your plans     
35:10     
like for the rest of the gck we have a couple more we have an extension a project extension so there's like four     
35:17     
more weeks so what are what are the plans going forward yeah so uh like first thing is I     
35:24     
want to clearly Define based on the metrics how different cells uh uh are so we have a bunch of     
35:31     
cells right if we can differentiate them uh and properly quantify them through     
35:37     
metrics so that is the first step which I want to do and and based on the     
35:42     
dynamic graphs uh specifically and like my main goal was     
35:47     
in the end was to make some uh uh like hypergraph uh like Define a hyper graph     
35:55     
and then model it so we can use it for Downstream tasks but I am still not unsure like after going through what     
36:01     
Downstream tasks we can do like you have mentioned it before like it sell tracking like that but that is what I     
36:09     
want to do in the end for to Define like a generalized model but I am still not sure about the     
36:16     
clear steps for that even though yeah we are actually very much on time yeah so I     
36:23     
guess like my suggestion would be to sort of take what you have like take those notes for example and maybe put     
36:30     
them in a formal format like maybe in a you could put them in a uh notebook or     
36:35     
something you know like an interactive notebook uh and just characterizes definitions maybe like go a little bit     
36:42     
into the sort of the plans forward for putting it into a pipeline or uh some sort of down set of Downstream tasks     
36:49     
just kind of think about what those might be and propose them and then you know we need to have by the submission     
36:57     
date why uh place a repository where you can submit and it doesn't need to be all     
37:03     
code but you know I think like what you have in terms of code and then some of     
37:08     
the notes and some of the other things I think that's good for a submission and     
37:14     
so you doesn't want to be able to package all that together with with like uh documentation and that and then that     
37:21     
should be enough for the project so you don't have to like you know you don't     
37:26     
have to do all this like above and beyond work you just need to get to a stopping point     
37:33     
where you can say this is you know kind of where we are right now because we had like one summer to do     
37:39     
this and I think we did some pretty made some pretty good advances this is kind of what the repository has in it uh you     
37:47     
know we have code we have plans for the future we have definitions and then you know that's all     
37:52     
sort of presented to this submission you know so the people uh evaluating the     
37:59     
project know that you did X Y and Z and then have some     
38:04     
documentation so that we have some idea where we left off what needs to be done     
38:10     
and so forth um now it's up to you whether you want to create formal issues on this you     
38:16     
might want to do that in the D graph repository I don't know if we have a project board in there I think we do but     
38:22     
um you know to have like a couple of things where okay if we want to go if we want to continue the project and I know     
38:28     
you want to work on a paper after the the coding period which you know is good     
38:34     
but we want to have some like technical issues to follow up on and have those in issue form so if we can do that that     
38:40     
would be good too okay okay so you're suggesting that we should post everything like the next     
38:46     
ideas on the board right yeah yeah those put those ideas out there formalized and then of course make sure     
38:53     
that your repository that you're submitting to gso is you know complete and has like a good set of stopping     
39:00     
points and you can just point out where you are and what you've done what you've     
39:06     
accomplished sure yeah broadly uh so like for the first steps I as you said I'll document these notes uh completely     
39:14     
and uh try to have some visualizations along with it I think that would be useful uh to understand and yes and then     
39:20     
use that board to Define clearly what a jacket you want uh so on like as a     
39:26     
project goes okay so a couple things I'd like to     
39:33     
finish up with here um the first thing is is that we have uh a number of poll     
39:39     
requests for dor graph uh thank you to Pocky and mahul for making their poll     
39:44     
requests now we have a few more weeks to gck left but I wanted to point out that     
39:50     
we've got a number of nice PO requests here and Mah of course making a PO request just this week and so we want to     
39:57     
get this all done um in four weeks so we're going to have more poll requests     
40:02     
to the daph repository and if you're interested in contributing to the divoc craft repository you're welcome to go     
40:10     
peruse the repository see what we've been doing over this summer and past     
40:15     
summers and um you know find a place to contribute     
40:28     
so the first thing I'd like to talk about in this collection is this uh Wikipedia article on     
40:34     
connectivity so we have uh this article this is on graph Theory and this is just     
40:40     
you know kind of an overview of what's in the textbook so I just wanted to go over this first to kind of get us     
40:46     
oriented to some of these other things I'm going to present so you know we talk about     
40:51     
connectivity and connectivity is basically where you have a number of nodes that are connected byed edes so     
40:57     
you have these edges that connect nodes you have in this diagram in particular     
41:03     
you have a number of sub networks which are uh highly connected sets of nodes     
41:08     
that are then connected themselves by these weak connections between them so you have these gray you know sub     
41:16     
networks or sub uh areas of connectivity and then you have these weak connections     
41:22     
with the uh ver with the edges connecting them so there's a consequence     
41:28     
to this which is that these patches are weakly connected that is if I cut this     
41:37     
edge here I end up with two uh sub networks     
41:42     
that are not directly connected they're still connected indirectly but they're not directly     
41:48     
connected so this means that you know when we have this weak connectivity where we have a single edge that     
41:54     
connects to sub networks we can cut it as then we end up with these distinct     
41:59     
structures and in this case they're indirectly connected so they're still connected you just need to go through     
42:04     
this inner immediate sub Network and so that has consequences for the path length between uh you know different     
42:12     
ends of the network so the path length is longer so in this in the first case where we have this um this Edge that's     
42:19     
still intact the path length across the network is three if we cut that uh Edge     
42:27     
and we navigate across the network the path length between this     
42:32     
node here this node here is five so it makes the path length     
42:37     
longer it also has to do with network flow so the flow of things between the uh nodes is you know more circuitous     
42:47     
it's more obstructed and so forth so this weak connectivity is very important     
42:52     
even though it's maintained by maybe a single edge so this article they talk about     
42:58     
like you know this sort of strategic cutting of of edges and of course you end up with this     
43:05     
um you know this model where you can isolate different nodes so in this case     
43:10     
we have with vertex zero this graph is disconnected so if we have zero that's connected by one Edge and we cut the     
43:16     
edge that Vertex or node is separated from the rest of the network and so it's     
43:22     
interesting how you can do things like this to network topologies and of course the edges as we talked about in Mah's     
43:29     
presentation you know we have you know weights on those edges so in some     
43:34     
context especially in biological contexts those edges might disappear in certain cases like if we talk about like     
43:42     
modeling a lineage tree using uh graph Theory you know some of the line you     
43:47     
know some of the cells in the lineage tree die off or divide so they're no longer there so those edges disappear so     
43:54     
you may end up in cases like that with disconnect networks maybe temporarily or     
43:59     
maybe permanently and that's interesting from not just a graph Theory perspective but a biological perspective as     
44:06     
well so you know we talk about connected vertices and graphs here they talk about like how you have things that are     
44:13     
connected disconnected and that's an important part of looking at networks you have components and cuts so a     
44:20     
connected component is a maximal connected subgraph of a undirected graph     
44:26     
so this is where we have this maximum size of a connected subgraph so in this     
44:32     
case uh this this is all a connected component because these things are connected in the case where I cut this     
44:39     
Edge then these things are connected but not the whole thing it's just kind of you know once you start cutting edges     
44:47     
you start getting connecting components which are smaller and you know the connected component idea goes back to uh     
44:54     
Reni who def who proposed this sort of large uh component or maximal component     
45:01     
of a network and so if you're looking at networks where you know these edges are changing they're they're dynamically     
45:08     
shifting they're being cut they're being generated you get these different connected components over time so this     
45:14     
is an interesting feature of our hyper networks because remember said this kind     
45:19     
of resembles a hyper Network because you have these subgraphs which have these     
45:25     
gray areas and these gray areas you can think of them as hyper hyper nodes although they're not technically hyper     
45:31     
nodes you can think of this as a hyper graph and that these are hyper noodes with nodes inside of them that are     
45:37     
interconnected that also are connected to other hyper nodes or nodes in other hyper nodes and so when we think about     
45:44     
cutting these connections we not only think about cutting the connections between subgraphs but also cutting the     
45:49     
connections between hyper nodes so that's where I'm kind of going with this the second thing about this     
45:56     
Wikipedia article is talking about this idea of hyperconnectivity so hyperconnectivity is not the same as     
46:04     
what we're talking about when we talk about hyper graphs but there's this idea of hyperconnectivity     
46:09     
that's distinct from something like super connectivity so basically hyperconnectivity is where you know a     
46:16     
graph is said to be hyperconnected or hyper K if the deletion of each minimum     
46:21     
vertex cut creates exactly two components one of which is an isolated vertex so up here we have this example     
46:29     
where there's an isolated vertex because we cut an edge and we we cut that vertex     
46:35     
out of the network and it's now its own thing um and then of course we have     
46:41     
hyperconnected or hyper conditions we have uh semi     
46:46     
hyperconnected conditions or semi hyper K conditions if any minimum vertex cut     
46:52     
separates the graph into exactly two components so instead of something where we have an isolated node we end up with     
46:59     
something like this or if we cut this Edge we have two sub networks or two subgraphs and of course what that means     
47:06     
is that we also have in the hyper graph case we have two hyper nodes where if     
47:12     
you cut this connection you end up with two separate hyper nodes so this all applies to hyper graphs as well as     
47:19     
regular graphs but hyperconnectivity I'm not quite sure where it fits in and I'd     
47:24     
have to do some more reading on this but I think it has a lot you know I think that mul's work can benefit from this     
47:31     
thinking about this in this way the second paper I want to talk     
47:37     
about is connectivity and hypergraphs so this is a paper from the Canadian mathematical uh bulletin from 2018 and     
47:45     
it talks about connectivity and hypergraphs so let's just read through the abstract and see where we end     
47:51     
up um so in this paper we consider two natural Notions of connectivity for     
47:57     
hypergraphs weak which we've talked about which is where you're connected by a single edge and strong where you would     
48:04     
have multiple edges that are kind of in this you know where your maybe your two     
48:09     
subgraphs are connected by multiple edges so it means that if you cut one you still have others and it's robust to     
48:16     
that cutting we prove that the strong vertex connectivity of a connected hypergraph     
48:22     
is bounded by its weak Edge connectivity thereby extending etherum Whitney from graphs to hyper graphs so it means that     
48:30     
we can think about this strong vertex connectivity of a connected hypergraph which is uh where connected hypergraphs     
48:37     
are tend to tend to have these strong kind of connections and this uh extends     
48:43     
this theorem of Whitney I'm not familiar with that from graphs to hyper graphs we find that while determining a minimum     
48:49     
weak vertex cut this can be done in polinomial time and is equivalent to     
48:54     
finding a minimum vertex cut and the two section of the hypergraph in question so     
48:59     
what they're talking about here is they're talking about uh this is done with an algorithm where you're cutting     
49:07     
optimally or you're cutting in certain places in the network and this is a polinomial Time process so it's you know     
49:14     
I guess it's tractable but it's not always tra depending on the size of the network I guess uh it depends on whether     
49:20     
or not it's tractable and is equivalent to finding a minimum vertex cut in the two section of the hyper graphing     
49:25     
question okay so determining a minimum strong vertex cut is NP hard for General     
49:32     
hypergraphs so this is the point here if it's small if the network is small or if     
49:38     
it's a regular graph it might for small networks be uh tracable but in terms of     
49:45     
like uh a minimum strong vertex cut so if you have a Network that has multiple     
49:50     
connections between its sub networks or its hyper nodes uh that finding that     
49:56     
strong ver Tex cut is NP hard for General hypergraphs so this becomes an NP hard problem in hypergraphs this is     
50:03     
just you know again thinking about the consequences of these sorts of Notions     
50:08     
of connectivity for hypergraphs moreover the problem of finding minimum strong vertex Cuts     
50:15     
remains MP hard when restricted to hypergraphs with maximum Edge size at most     
50:21     
three so this is even when you get actually when you in hypergraphs you get very relative ly small hypergraphs small     
50:29     
Edge size that are connecting the two uh subgraphs you you know even when you     
50:34     
have that small number of connections so it doesn't have to be you know the     
50:40     
strong connectivity it doesn't have to be that great it just you know it just     
50:45     
has to be a little bit strongly connected and it becomes an MP hard problem so this is a problem with you     
50:52     
know running an algorithm to try to find those optimal Cuts or whatever so this is something that think about when we     
50:57     
think about connectivity we can think about sort of the mechanics of connectivity we can also think about how     
51:03     
we would understand these uh in terms of cutting the uh     
51:09     
edges we also discussed the relationship between strong strong vertex connectivity and the minimum traversal     
51:14     
problem for hypergraphs okay so they talk about that in this paper the minimum traversal     
51:20     
problem which is of course the path length which I talked about the minimum path length and that's important in     
51:25     
finding the the diameter of the graph or in this case the hyper graph and this is     
51:31     
something that um Mah talked about in terms of walks so that's an important     
51:36     
point there I might help him kind of uh Shore up that definition showing that     
51:42     
there are classes of hypergraphs uh for which one of the problems is NP hard while the other can     
51:48     
be solved in polinomial time so this is again where you know when you have uh     
51:54     
two different their classes of hypergraph sometimes you have polinomial time which is tractable for small networks and then     
52:01     
for the larger cases you have this NP hard issue so that's not necessarily     
52:06     
tractable with using a conventional algorithm so this is an important point turn kind of talking about hypergraph     
52:14     
connectivity with respect to sort of algorithmics and some of these other things that we'd be interested in um for     
52:21     
developing this this type of hypergraph     
52:29     
so the next paper is this analytical connectivity in uniform hypergraphs properties and computation this is     
52:36     
another paper this is from um uh     
52:41     
which this is from numeric linear algebra applications so this is a mathematical journal and this kind of     
52:48     
goes through this idea of antic connectivity which is AC defined via     
52:54     
solving a series of constrainted polinomial optimization problems again you're using polinomial optimization to     
53:01     
sort of and you're constraining it so it's you know a specific set of solutions here uh if you use this type     
53:09     
of anotic connectivity which they Define in the paper this serves as a measure of connectivity in hyper grips so we can     
53:16     
actually look at analytic connectivity we can use constrained polinomial optimization so it's a a case of the     
53:23     
first uh set of conditions in the last paper and this gives us some measure of     
53:28     
connectivity in hyper graphs how to compute such a quantity efficiently is important in practice and a theoretical     
53:35     
challenge as well due to the non-convex and combinatorial features of its definition so this is a non-convex     
53:42     
problems or combinatorial problem as well so this is something that we have to consider when we constrain the     
53:50     
problem or think about formulating the problem in in um what something like     
53:57     
what Ms do in this article we first perform a careful analysis of several     
54:03     
widely used structured hypergraphs in terms of their properties and heris upper bounds of AC's or analytical     
54:09     
connectivities we then prevent an apine scaling method to compute some upper bounds of AC's for uniform     
54:17     
hypergraphs to testify the tightness of the obtained upper bounds two possible approaches to the polia theorem and     
54:23     
semi-definite programming respectively are also proposed to verify the lower bounds generated by the upper obtained     
54:30     
upper bounds minus a small Gap so they do these numerical experiments on synthetic data sets they demonstrate the     
54:38     
efficacy of the proposed method with this kind of technique uh they also apply their method and hypergraphs     
54:44     
constructed from social networks and text analysis so these are specific types of hypergraphs not uh synthetic     
54:52     
data but from Social Work social networks and text analysis and this is of course quite different from what     
54:58     
we're trying to do but it it might be useful to look at what they've done to detect the network connectivity and rank     
55:04     
the keywords of in the text analysis example respectively so this     
55:14     
is so this is an example of connect connectivity in hypergraphs you have     
55:19     
these hyper uh nodes and they're connected this in these ways the hyper     
55:25     
nodes are these like circles around the nodes you can see that they're connected weakly connected and strongly connected     
55:32     
and you know you have these different ways of uh looking at these different topologies and then measuring um their     
55:39     
average degree okay the final two papers I     
55:46     
wanted to talk about uh I don't even want to really go into this paper too much but I do want to point this out     
55:52     
this is the geom uh geometry connectivity of hypergraph uh this is an archive paper from 2019     
56:00     
and it kind of goes over uh some of the ways that they're modeling this using a leoan tensor and uh you know so this is     
56:07     
kind of going over geometric connectivity I talked about geometric connectivity a little bit in the um in     
56:15     
the uh main meeting but this is basically talking about this finding     
56:21     
room feedler where they pointed out that a graph G is connected if and only if     
56:27     
the second smallest igen value of the laian Matrix LG is more than zero this     
56:34     
Igan value which results is called the algorithmic con algebraic connectivity of graph G denoted as Alpha G usually     
56:42     
this conclusion is called the fet theorem so they're using you know this might be above like what we're trying to     
56:48     
do in in our we're going to write a paper after this so we might you know we might draw from these methods but um I     
56:55     
just want to point out that this exists the last paper is this idea of     
57:02     
random contractions in sampling for hypergraphs and hedge     
57:07     
connectivity so this paper I don't I know where this was published let's     
57:13     
see okay so this paper I I don't know where this was published but this is uh     
57:19     
basically talking about these different types of connectivity so this is a hedge graph where you have these hedge cuts     
57:27     
and they show like how you can break decompose the network into different parts or decompose it into individual     
57:34     
nodes so when I just go over the abstract I just wanted to point this out in terms of um you know because this has     
57:41     
uh results that are relevant to hypergraph connectivity so they talk about this in terms of um so I'll go     
57:49     
over the abstract in the introduction and we'll talk about its relevance so we initiate the study of     
57:56     
hedge connectivity of undirected graphs motivated by dependent Edge failures and     
58:01     
real world networks in this model edges are partitioned into groups called Hedges so you can see the red edges here     
58:08     
these Hedges that fail together so if you cut these two uh edges here you end up with     
58:16     
these node uh sets of nodes that form these Hedges and the hedges fail together because you cut apart their     
58:24     
connectivity um the h connectivity of the of a graph is the minimum number of Hedges is removal disconnects the graph     
58:32     
entirely so this is actually you're cutting these Hedges here you end up with these Hedges and they     
58:39     
fail um we give a polinomial Time approximation     
58:46     
scheme so Hedges that F together so you get these Hedges here that are cut they     
58:53     
fail together they cut this network in two parts and so it's basically     
59:00     
decomposing this into a by graph the Hedge connectivity of a graph     
59:07     
is the minimum number of Hedges whose removal disconnects the graph so you want to find the minimum number of     
59:12     
Hedges which disconnect the graph in this case it's two because you have these two that can't be either directly     
59:19     
nor indirectly connected through a single edge we give a polinomial Time     
59:24     
approximation scheme in a qua polinomial exact algorithm for hedge connectivity     
59:30     
this provides strong evidence that the Hedge connectivity problem is tractable which contrasts with prior work that     
59:36     
established the intractability of the corresponding s minus t mincut     
59:42     
problem so this is where uh this is similar to what we're talking about with the MP hard stuff uh with with the     
59:49     
hypergraph stuff in one of the previous papers our techniques also yield new     
59:54     
combinator algorithmic results in hypergraph connectivity next we study the behavior     
1:00:00     
of hedge graphs under uniform random sampling of Hedges uh so we sample the edges and see     
1:00:06     
which ones are the hedges we figure how few we need to cut to end up with two     
1:00:11     
separate graphs we show that unlike graphs all Cuts in the sample do not converge with     
1:00:17     
their expected value in hedge graphs nevertheless the Min cut of the sample doesn't indeed concentrate around the     
1:00:24     
expected value of the original mincut this leads to a sharp threshold on     
1:00:29     
hedged Survival probabilities for graph disconnection to the best of our knowledge this is the first Network     
1:00:35     
reliability analysis under dependent Edge failures so we're trying to look at     
1:00:40     
is we're actually looking at the reliability of graphs if we have a graph and we say that they're connect it's     
1:00:46     
fully connected we can look for the edges or we can look for these Hedges which are edges that if you cut them the     
1:00:54     
network uh basically basically is bisected and of course the network would fail if you think about like a power     
1:01:00     
Network where you have you know maybe one or two connections so it's fairly weakly connected you cut those two     
1:01:07     
Hedges and the the the different parts of the network fail to connect so you     
1:01:13     
cut the network and two effectively so that's what they're trying to do and they you know this has a number of uh     
1:01:19     
applications to different types of networks social networks utility networks even biological networks where     
1:01:25     
you you have you know like maybe a connectome that has um you know that has     
1:01:30     
to be connected and if you cut it in the right in the wrong place you cut a certain Edge you can BCT that Network     
1:01:38     
and remove function I'm thinking specifically of networks in the spinal cord uh you know like basically failing     
1:01:46     
in terms of function so this this talks about hedge connectivity in undirected graphs     
1:01:53     
consider an invertex graph or multi-graph gals V where M edges have     
1:01:59     
been partitioned into groups of called Hedges so we partition these edges into Hedges into these groups of Hedges we     
1:02:06     
say G is K hedge connected if it is necessary to remove at least K Edge groups or hedges in order to disconnect     
1:02:12     
G so you find all the hedges you find out which Hedges are more or less likely     
1:02:18     
to be a part of the sort of removal process so if you remove the hedges um     
1:02:24     
you know how many Hedges do you need to remove to disconnect G so you have G and G Prime as a     
1:02:30     
result this definition generalizes classical graph connectivity where each Hedges a single edge and hypergraph     
1:02:38     
connectivity so before we were just talking about regular graphs now we're talking about hypergraphs and in     
1:02:43     
hypergraphs instead of where each Edge is a where each hedge is a single edge in hypergraphs each hedge is a spanning     
1:02:52     
subgraph on the vertices of a hyper Edge so this is where we have these hyper edges which are single lines between two     
1:03:00     
hyper nodes those edges contain all these connections between the nodes     
1:03:06     
within the hyper nodes and if you cut that you know you can actually have the     
1:03:13     
Hedge consists of multiple connections so it's interesting that in hypergraphs     
1:03:19     
this technique can also be used but it has a consequence of cutting a bunch of     
1:03:24     
edges at once okay so it is a broader it is broader because a hedge can spin multiple     
1:03:30     
unconnected hyperedges so this is where you have these different hyper edges that um you know this is interesting     
1:03:38     
where these Hedges are actually less selective in terms of how they're     
1:03:44     
connecting or managing connectivity so you know this is the way they're kind of formulating this uh the main motivation     
1:03:51     
for a study of hedge connectivity crims from the dependence among Edge failures observed in real world networks Hedges     
1:03:58     
model the simplest form of dependence that sets of edges fail together so you find the set of edges that are kind of     
1:04:05     
in the same dynamical mode or the same functional mode you cut those and you     
1:04:11     
can trigger a failure the classical notion of graph connectivity or the minimum number of     
1:04:17     
edges is removal disconnects a graph can be very a very weak approximation of the     
1:04:22     
robustness of a graph in this scenario so so this is the idea that you know graph connectivity or the sort of the     
1:04:30     
basic Assumption of graph connectivity which is the minimum number of edges where REM removal disconnects the graph     
1:04:37     
so if we have like you know our first example where we had these sub networks that were connected by one or two edges     
1:04:44     
if we just is find the minimum number of cuts that we need to make to disconnect     
1:04:49     
those graphs that's sort of the you know classical notion of how a graph is connected or how to evaluate     
1:04:56     
connectivity this is actually a weak approximation of the robustness of a graph for a number of     
1:05:02     
reasons um and this is of course due to to indirect connections or other types of things that you know so this is why     
1:05:08     
they're using this Hedges approach hypergraphs address part of this weakness but require all the dependent     
1:05:15     
edges to be connected to each other um while Hedges do not so in in     
1:05:20     
hypergraphs we have these dependent edges they have to be connected to each other in hyper in in hypergraphs Hedges     
1:05:27     
are not in that way in fact our techniques yield results in hypergraph connectivity as     
1:05:34     
well so we also know uh that by insisting on the fact that Hedges are disjoint we're not losing any generality     
1:05:42     
if Hedges overlap on an edge modeling the uh the fact the edge can fail as part of multiple groups so if we have a     
1:05:49     
bunch of hedge groups that we identify that are like okay if we cut these Hedges the network will fail and that     
1:05:56     
you know happens that one Edge is part of many groups of Hedges many possible groups of Hedges that just means that     
1:06:03     
that edge is May maybe it's very very important and if you cut that edge no matter what group it's a part of it's     
1:06:10     
going to result in the fail in the that one uh so this this kind of goes through this hedge technique they use random     
1:06:18     
contraction techniques to study hedge connectivity hedge is set to be cut if at least one Edge from the Hedge crosses     
1:06:24     
the cut to void confusion we use the term hedge cut to denote sets of Hedges and a cut or the term cut continues to     
1:06:31     
represent the set of edges respectively hyper edges crossing the     
1:06:37     
cut so I'm not going to get any any more in this I think it's it's uh pretty much     
1:06:42     
kind of where I want to stop um but again this relates to what Mah was talking about in the main meeting and so     
1:06:50     
you know if you have any questions please let us know
