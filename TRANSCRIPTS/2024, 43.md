## TRANSCRIPT    

0:00     
hello Hi how are you would you know anything about how to     
0:06     
use word and numbering uh     
0:13     
numbering yes a little bit I mean you have to go     
0:18     
to the menu and number and you can like configure the numbers yeah theot well I'm I'm doing a     
0:25     
thesis and there's called something called the front matter and it's in Roman numeral and then you have to     
0:31     
switch over to the other to regular arabe Arabic numeral numerals for the     
0:38     
rest of it how do you do that because I I yeah you have to uh do a page break or     
0:46     
a document break or something I think they call it a page break or no I guess did yeah so you do     
0:53     
the first part you break and then you do the second part yeah I know but um     
1:01     
it didn't work well okay so I don't I don't have it in front of me but there's a like a it's not actually because     
1:08     
there's a page break which is where you break to a new page and then there's like I guess like sorry I can't hear you     
1:16     
this thing has gone off beside me um say it all right so yeah they have like a     
1:23     
page break which is where sorry um sorry     
1:30     
okay somebody answered it can you please tell okay what did you say so they have     
1:36     
like a page break which is the uh where you can just break to the next page and then there's a document break where you     
1:43     
actually break the document like into two documents and you can like start off     
1:50     
like on the next page but it starts the document over and it's so maybe I need to look     
1:55     
for document break I think so yeah you'd have to yeah you have to look up     
2:02     
in the doc like in the uh let me look I can check     
2:08     
here there a very snippy Professor saying there's no time for coaching and we going the only problem I have is that     
2:16     
I can't get the page break to work right to start the     
2:22     
numbering actually called section break section break okay all right maybe     
2:30     
that's it I think so one fellow wants     
2:36     
me section Break um one fellow wants me to use a passive voice and one wants me     
2:43     
to put I in the um abstract     
2:49     
yeah uh what's the convention uh well we I usually do it as     
2:55     
the active so like it's like um I guess you could say I     
3:00     
because you're not working with colleagues you could put me if you had like     
3:05     
co-authors um but you know it's usually present tense so like uh like a     
3:14     
so I conduct or maybe uh conduct a an analysis instead     
3:20     
of an analysis was conducted so you do the the uh the present     
3:26     
tense you can use I because you know usually in papers people use we but     
3:31     
that's a with co-authors so you know it's so that that     
3:37     
the one Professor likes the two eyes I put in it in the abstract and the other     
3:44     
fellow says no I want a passive     
3:49     
voice yeah like don't know I don't more of a     
3:56     
problem of they can't agree     
4:04     
oh well I'm not sure what to do about that but anyway um I'll try for a     
4:11     
section break okay yeah that sounds good that sounds     
4:16     
good thanks I just like like this it's probably all like wrong anyway     
4:25     
so I'm going to have to fix it but oh um like for numbering     
4:33     
my equations I just put one two 3 four     
4:38     
Yeah well yeah that's how I usually do it I mean in the brackets yeah in the brackets anyways I     
4:45     
I'll just put the page and numbering in and H and sort of fix the abstract and handed     
4:52     
it yeah yeah yeah it's always that's one of the big challenges of like thesis     
4:58     
writing is like getting to do things that you wanted to do like for formatting     
5:04     
yeah well said I can't coach you handed in today is like really I've been     
5:11     
working on this stupid page page break thing for all weekend     
5:19     
yeah yeah doesn't matter which way I twist my tongue it still doesn't work so it must     
5:24     
be a section break never mind     
5:30     
say wbl yeah okay um well welcome uh so it looks     
5:39     
like Morgan's here Susan's here um     
5:44     
yeah so any any questions or issues like     
5:49     
to raise before we begin I wish I knew where to find     
5:57     
more data well grab of tissue when they're being tensioned     
6:03     
or compressed I really like to I've I've got about four or five     
6:10     
examples and it was hard to find and the one thesis I looked at     
6:18     
um was they were doing compression and they literally said due to the lack of     
6:25     
literature on this subject I am doing this project     
6:34     
yeah maybe I should put that in my conclusion yeah I don't I     
6:40     
have yeah I can quote the guy     
6:47     
anyways all right yeah well yeah that's always a thing with new areas is you     
6:53     
have to find the right data okay so yeah why don't we get     
7:01     
started um yeah so it's almost the end of the year uh I think we'll have one more     
7:07     
meeting after this um I think this is a pretty good year we had a lot of     
7:13     
interesting things he talked about a lot of theme kind of a lot of themes to     
7:18     
stretch out um I've done a little bit of uh like over like kind of recounting of     
7:26     
what we've been doing this year when I was doing uh preparing for the annual meeting meeting open or manual meeting     
7:32     
and uh yeah it's interesting we had a number of themes I don't have them with     
7:38     
me but I will maybe prepare something maybe for next week um you know we we     
7:45     
started off the year we were talking about different open source initiatives around openworm and Diva     
7:52     
worm we did a lot of work with the Google summer of code with uh     
7:58     
topological type model and um hypergraph models and then we've     
8:03     
been talking about um tensegrity and Me Cell Mechanics for most of the year uh     
8:11     
then not to mention a lot of the stuff with molecular biology and development so     
8:18     
there a lot of themes I'll I'll maybe get to that next time or maybe put out a     
8:24     
video on it on YouTube or something just kind of going through those themes and     
8:29     
you know where the sort of the interests lie you know because you kind of go from     
8:34     
week to week and you don't know you know where everything's accumulated but we can I'll do that     
8:41     
maybe next time so that's good um yeah so Morgan um and we were having     
8:49     
a conversation in the slack about the openworm annual meeting     
8:56     
and specifically a project that is sort of parallel to what openworm is     
9:02     
doing um and we'll get to that paper in a minute but it's it we at the open     
9:09     
roomm uh annual meeting we had this discussion or lengthy discussion about     
9:15     
some of the other initiatives that people were doing around sea elegans um there's a Chinese group and I     
9:22     
know we covered this paper that are doing things with some of     
9:27     
the openworm tools that is interesting I think we talked about that around the middle of the year     
9:33     
uh where they were doing work on they were kind of trying to develop their own tools and then they kind of used     
9:39     
openworm tools and then uh so the people at openworm were aware of that     
9:45     
initiative um and then there's this other initiative by a bunch of people uh like Adam marblestone Conrad     
9:54     
cing uh Neta Cohen who's actually on the open roomm scientific Advisory Board     
10:00     
and a lot of other people on this they call reverse engineering     
10:05     
the worm which we'll get into that paper and talk a little bit about what they're doing we talked about this as well a     
10:13     
while back it was kind of an informal discussion that um Conrad cording     
10:19     
brought up um and you know he put something out like a a Word document and it was kind     
10:25     
of rough and ready so it wasn't like anything formal this is a more     
10:30     
formal uh statement about it but what they want to it's a vision paper where     
10:36     
they talk about how to not only build a model of celegans but also to do     
10:43     
experiments um in terms of the connectome to look at how each neuron     
10:49     
functions in the context of different manipulations so you'd have a lot of uh     
10:55     
what they're thinking of is really kind of bringing optogenetics to bear     
11:00     
in stimulating individual neurons and looking at different     
11:05     
circuits and what behaviors they generate so it's very interesting     
11:10     
um so this is the paper here the time is ripe to reverse engineer an entire     
11:16     
nervous system simulating behavior from neuro interactions this is a number of people     
11:23     
um gal haspel is the first author Ed Boyen is on this George chur     
11:29     
Neta Cohen as I mentioned before Daniel colen Ramos is at Yale he's a seans     
11:36     
person uh we have uh let's see Edwardo was skiro has worked with open worm in     
11:41     
the past uh Sean Locker he's a seans person Adam marblestone who does a lot     
11:47     
of synthetic biology uh let's see     
11:53     
Lerman who's a sea Elegance person uh Avatar yini who's worked with     
12:00     
openworm in the past and Conrad cording of course does a lot of the stuff with     
12:07     
uh neurom match and that then Manuel Zimmer who's also worked on with Avatar     
12:13     
y mini on some of these things in the worm so there a lot of seans people     
12:18     
synthetic biology people uh and you know Neuroscience people so this is really     
12:24     
interesting they have you know we talked about another Vision paper people talked     
12:29     
about using like deep learning for something or another and it was like you     
12:35     
know the vision paper was basically stating your vision for something it didn't really have a lot of like you     
12:40     
know we're going to actually show how this is done it's just kind of like this is what's needed so just to give that     
12:47     
context okay so the abstract uh reads so just like electrical engineers     
12:53     
understand how microprocessors execute programs in terms of how transistor currents are     
12:59     
affected by their inputs neuroscientists want to understand Behavior production in terms     
13:06     
of how neuronal outputs are affected by their inputs and internal States so you     
13:13     
know we think about so this is interesting context Conrad cording was a     
13:18     
co-author on a paper several years ago um called uh could neuroscientists     
13:25     
understand a microprocessor and the idea was if you took a neuroscientist with training in     
13:32     
looking at circuits you neural circuits and you dropped them in front of a     
13:37     
microprocessor and they had never seen a microprocessor before could they figure out how the microprocessor works by kind     
13:45     
of studying the output studying what the microprocessor does internally and then     
13:50     
you know providing inputs to the microprocessor that's how the this is kind of the idea here so     
14:00     
you know they're kind of building on that idea but basically you know if you think about what neuroscientists do when     
14:06     
you do experiments behavioral experiments is you might have like you know you might have like two uh     
14:14     
different strains of a mutant or you might have a wild type and a mutant you might have some condition     
14:22     
where you know you have like an expert in a novice or you might have like a a     
14:29     
you know like some sort of neurodegenerative disease and a normal     
14:35     
phenotype so you have these differences that you use in an experiment and it's really about experimental design so you     
14:41     
have these different conditions then you have some common behavioral task you     
14:47     
keep that controlled then you have the behavioral task that's performed there's something     
14:53     
that goes on inside and then there's a behavioral output and you compare the behavioral output and then you try to     
14:59     
infer what's inside the brain trying to you know that that make accounts for this difference or non- difference so     
15:07     
you know we can do different use different neuroimaging techniques or whatever to get at that and you know we     
15:14     
can also use optogenetics to stimulate certain neurons if we wish but the idea     
15:20     
is that we can manipulate things we can look at the behavioral output and then we can try to using those together to     
15:28     
try to get to like an answer of how that circuit works so it really isn't that much     
15:35     
different than how like neuroscientists do science I don't know why they had to     
15:40     
use the electrical engineering metaphor but maybe it's cleaner anyways this dependency on     
15:46     
neuronal outputs on inputs so neural outputs are dependent on inputs so if I     
15:52     
give you an input that is you know uh of a certain strength of a certain     
15:59     
um you know amplitude I should expect some sort of output that may be you know     
16:06     
proportional and you know they're nonlinearities in in in the brain so I don't want to Discount that but     
16:13     
basically they're making this case the inputs condition outputs or outputs are     
16:20     
dependent on inputs uh these dependencies can be described     
16:26     
by a state dependent input output or IO function however to reliably identify     
16:32     
these IO functions so their goal is to create these IO functions we need to perturb each input     
16:40     
in combinations of inputs while observing all the outputs here we argue that such     
16:46     
completeness is possible in celegans a complete description that goes all the way from the activity of     
16:51     
every neuron to predict Behavior so I think they kind of arguing for sort of     
16:57     
an ATT Turing completeness of Behavioral experiments in other words you know in     
17:04     
Turing completeness you can you have like a set of functions that produce all     
17:10     
possible outputs and usually in like computer science it's turning complete so you can     
17:17     
like if a simulation is turning complete you can simulate the entire system or     
17:22     
the entire thing that you're trying to simulate in this case this is where we have the sort of Behavioral in     
17:29     
completeness if we want to call it that it's really maybe Behavioral completeness or something like that     
17:35     
where you have enough data on the different perturbations that allow you to observe     
17:42     
all outputs so you know you don't have any missing States and you don't have any unexpected     
17:50     
outputs so that's what they're trying to do and so they're they're going to build an experimental test bed they're you we     
17:57     
characterized the connected and see elegans low enough so that if you kind     
18:02     
of do these have this experimental framework you should be able in principle to do     
18:09     
this here we argue that such completeness is possible in C elegans a complete description that goes all the     
18:15     
way from the activity of every neuron to predict Behavior so we have the in     
18:20     
information about every neuron in the connecto we have a lot of information about the activity and what we want is     
18:27     
this complete description of all the activity and in a way that predicts Behavior the established and growing     
18:34     
toolkit of optophysiology and by that they meet optogenetics and other Optical stimulation techniques other Optical     
18:41     
reporting techniques can noninvasively capture and control every neuron's activity and     
18:47     
scale to countless experiments the information for many such experiments can be pulled while     
18:54     
capturing the interindividual variability so they're interested in taking sort of the uh you know the     
19:04     
ability to sort of control every neuron's activity to turn it on and turn it off at will to record all the     
19:11     
different sort of contacts that are needed to predict     
19:16     
behaviors and then also to look at interindividual variability so that you know we have differences in a lot of     
19:24     
celegans we have mutants defined mutants we have wild type     
19:29     
strings we have males and hermaphrodites we have different just kind of     
19:36     
interindividual uh quirks of seans we talk about seans being sort of this you     
19:43     
know deterministic having this deterministic biology but there are differences in     
19:49     
sometimes in how the brain produces behavior um so there are a lot of things     
19:57     
we can you know a lot of sort of individual variability things we need to     
20:04     
accompl okay so because neuro identity and function are largely conserved     
20:09     
across individuals but not you know it's not complete conservation what they mean     
20:15     
by conservation is that neuro identity and function don't change across individuals and you know unless you're     
20:22     
dealing with a mutant or sometimes in males it's different than     
20:27     
hermaphrodites so just just like electrical engineers use transistor IO functions to simulate program execution     
20:34     
we argue that neuronal IO functions can be used to simulate the impressive breadth of brain States and behaviors of     
20:42     
Cl so there argument is basically that you can do it's not really building a simulation     
20:49     
per se it's building the conditions for a simulation so they're backing up from     
20:57     
what openworm is kind of doing and saying we can actually provide this     
21:02     
framework for you know we have an organism that has some individual     
21:08     
variation but not too much we know the connecto we know kind     
21:13     
of what it does so we can apply these Technologies to sort of manipulate the internal State     
21:19     
enough so that we can produce all sorts of behaviors but more than that we can     
21:25     
produce these input output functions so that if I give you some input I can predict the output pretty     
21:32     
well so that's what they're trying to do here uh so they talk about the     
21:38     
introduction uh they actually talk about this paper U the can a neuroscientist     
21:44     
understand a microprocessor uh then they talk about for such a simulation one needs a list     
21:50     
of all components or a net list and the input output functions of all the elements the simulation is then the key     
21:57     
tool for understanding information processing in the microprocessor and asserting that it is correctly     
22:02     
engineered so the idea is that you have to sort of provide a listic components and input output functions to a     
22:10     
simulation and from that you can then build you can understand what a microprocessor does you can understand     
22:16     
all the output States and what they what what where they come from     
22:23     
uh then they have this part uh when philosophers talk about understanding and explaining they usually distinguish     
22:29     
many kinds thereof according to Tin virgon there are four categories of explanation so these are 10 virgins for     
22:37     
explanations divided along axes approximate to Ultimate and static to     
22:43     
Dynamic so we want to maybe say understand the philogyny of the nervous     
22:49     
system The evolutionary trajectory that made the nervous system the way it is another goal is to understand how     
22:56     
development or ontogeny gave rise to the individual animal as it is now so within the lifespan how did     
23:03     
that nervous system develop a third goal is understand the function or adaptation of the nervous     
23:10     
system so you know once the nervous system is in adult form how does it     
23:15     
adapt to physiological conditions to environmental conditions and then lastly     
23:21     
the goal is to reveal mechanism or causation so how does something actually work what comes before what what causes     
23:30     
what this goal is usually taken as describing the function of something in terms of causal interactions between the     
23:36     
involved components uh so that that's exactly what they're doing and then of course     
23:43     
the model of the neuro understanding the neuroprocessor is very much like how other Sciences     
23:50     
find um relationships between different things so they're drawing inspiration     
23:56     
not only from electrical engineering but from chemistry from physics and so     
24:01     
forth so when neuroscientists a to understand brains following Tim Burgin for questions they thus use many     
24:08     
different levels and definitions of understand for some understanding me the ability to fix diseases for others     
24:16     
understanding means knowledge of involved representations and yet for some understanding means the ability to     
24:21     
simulate an analogy to the electrical engineering case the ability of faithful     
24:27     
simulation would then also come with solutions for fixing problems predicting the nature of brain representations and     
24:34     
a range of approaches to deep in our understanding in the brain so that's     
24:39     
where they kind of uh kind of leave it for that and then you know they they     
24:44     
kind of talk about um why you should reverse engineer a nervous system     
24:51     
so um so a central role of systems in computational Neuroscience is the model     
24:58     
nervous systems convert stimula spontaneous activity and internal States     
25:04     
into things like coordinated muscle contractions and other types of behaviors so their inputs to behaviors     
25:12     
are kind of like raw materials and then there's this product which are you know     
25:18     
different coordinated behaviors so you might have say light stimula you might     
25:23     
have some spontaneous activity among the neurons and then you might have internal States which are not spontaneous not     
25:31     
stochastic they're actually like intentional States and you know a light     
25:36     
stimulus might say condition this internal State into some sort of     
25:42     
response paradigms or response mechanism so you might have an internal     
25:49     
State and you might have spontaneous activity and the presence or absence of     
25:54     
light will turn on or turn off this internal state so you end up with     
26:00     
two states on and off you end up with spontaneous activity that might actually also tip uh the system from one state to     
26:08     
another or it might interfere with the stimulus but in any case you have these     
26:13     
three components and then those things or lead to things like coordinating muscle contractions or other types of     
26:21     
behaviors so you know that's kind of the idea uh they actually talk here about     
26:28     
the brain initiative um where you know we're trying to develop new large scale neurot     
26:35     
Technologies and other funders like the human brain project microns and the     
26:41     
Simons Global brain collaborations where they're also trying to reverse engineer     
26:46     
brain so that's and then success in Reverse neuroengineering is actually having this     
26:53     
kind of um you know ability to predict outputs     
26:59     
from inputs so um let's see uh we consider each neuron     
27:08     
and muscle cell to be Computing its output as as a function of the activity of the input cells and spontaneous     
27:15     
activity so it's you know you have output equals input uh plus some stochastic term or it     
27:24     
could be M multiplicative if you wish but basically that's the equation that we're using um and then as such it is     
27:33     
characterized by a spatial temporal function mapping input traces into an output Trace so you have the spatio     
27:41     
temporal uh input which is space plus time and then you have this output which     
27:48     
is this output Trace which is I guess also spatio temporal in space and time so if you     
27:56     
have an input of light stimulus the light stimulus has a source in space it     
28:02     
can turn on and off with respect to time and then that converts through this uh     
28:08     
stochastic function this random function which adds noise to the system and then     
28:13     
you end up with this output that also is located in space and time so if there's a source of     
28:19     
light I you know to my you know uh 30° to my left and you know up above the     
28:26     
Horizon I'm going to move move towards that light source perhaps I I I coordinate my limbs I move towards the     
28:34     
light source and sometimes there's noise like for example sometimes it's confusing as to where the light source     
28:40     
is there might be multiple light sources so you have to decide which light source     
28:46     
you want to go to and that's how you get this sort of input output the input is     
28:51     
spao temporal it it's processed in this uh in terms of this function in terms of     
28:58     
noise and then you have the spatio temporal output so that's what you're trying to     
29:04     
reverse engineer here and then and then of course you have to think about the output Trace IO     
29:11     
function which represents both synaptic and non synaptic effects so this mapping     
29:16     
is very simple in terms of an equation but then the equation you could unpack this into um you know you can unpack     
29:24     
this stochastic term into like a stochastic term and then some synaptic     
29:30     
and non- synaptic things so you have say for example if you had like a neural     
29:36     
network you would have like uh some stochastic term plus maybe the weights     
29:42     
of that Network which would be very analogous to synaptic uh function and     
29:47     
then non- synaptic effects which would be something else that we could use to inform the network which we usually     
29:54     
don't use in neural networks but we could put one in so the non synaptic effects are things like neuropeptidergic     
30:00     
signaling or spontaneous activity which we could use the the uh random noise we     
30:06     
could use some other set of terms to fit that together and then say that plus the     
30:13     
input gives us the output so again I don't think it has to be additive because a lot of this you     
30:21     
know this is all processing and so it's probably there's some nonlinearity here this reductionist framing reverse     
30:27     
engineering consists of figuring out the input output mapping for all neurons and muscle cells as well as the inputs from     
30:34     
the world or system identification thus reassembling the collection of iof functions into a robust simulatable     
30:42     
model that can exhibit key behaviors when connected to a simulated body so in     
30:48     
figure one they show this um moreover behavioral variability will be recapitulated by drawing parameters for     
30:55     
multiple simulations from the empirical variability of iio functions to be     
31:00     
deemed successful this working model should recapitulate behavior and behavioral variability under a range of     
31:07     
conditions stimul and perturbations so figure one is down     
31:18     
here right here so this is their model uh overview     
31:25     
of the proposed approach demonstrating how Imaging recording and perturbing modeling and simulation     
31:31     
inpl so the first thing they want to do is do imaging they want to image a bunch of worms you can image the uh nervous     
31:37     
system you can image do this optogenetic stimulation     
31:42     
um well the Imaging is really just to get a like I guess a CO register a lot     
31:48     
of the things are going to be doing with recording and perturbation uh but basically there's an     
31:53     
Imaging component then there's recording and perturbation you can do that during the iming step where you're recording     
31:59     
from each neuron you're perturbing it with light you're getting this sense of how the neuron responds then you have     
32:07     
this modeling and evaluation and they build their functions um to predict the model     
32:14     
outputs but then they also have this ground truth which is the recording and perturbation step so you basically you     
32:23     
get a bunch of data from the Imaging uh you get model outputs you put this into     
32:29     
a model you get the outputs you simulate those you also have a ground truth which You observe from the Imaging and then     
32:35     
you try to compare model an experiment and then of course simulation you     
32:42     
further put this into like a digital model of a worm and then you do this real world behavioral validation where     
32:49     
you compare it to the real world and you likewise do this model versus experiment stuff so that's that's     
32:57     
where we have figure one so they propose a bunch of things that we need to do for this uh again this is kind of you know     
33:05     
very SE Elegance like this is a lot of stuff that you know open worm has been doing for a     
33:12     
while I think the Innovation here is kind of the manipulation of the     
33:18     
behaviors getting different Behavior getting this catalog of behaviors basically making this more or less turn     
33:24     
incomplete that's what they're proposing far as I can tell anyways uh I may not     
33:30     
be doing it justice but I I think then they have this bit about power calculations so this is where you're     
33:37     
really trying to get statistical power and you're trying to figure out how how much experimentation you need to do not     
33:44     
just to produce these functions but to get some statistical power so you can make statements about these things     
33:50     
instead of just kind of showing a proof of concept and this is where it gets interesting because you know with a lot     
33:57     
of behaviors to really characterize them fully you don't just need a bunch of     
34:03     
different behaviors or all the different behaviors that exist but you need a lot of observations of them so you know that     
34:10     
something is not just a statistical anomaly or you know it's you know just     
34:15     
kind of some random Behavior you can determine random behaviors from non-random behaviors so that's where you     
34:21     
need your power calculations you need to figure out how many experiments you need to do how long     
34:27     
those experiments need to be and how many cgans need to be involved in these     
34:32     
experiments so they're really focused on power calculations here this is where we     
34:38     
kind of you know if you're Fami if you're familiar with statistical power you know that this is just a tool to     
34:44     
tell you how robust your result will be once you make a statistical test so if     
34:50     
you make a statistical test then you get a significance and the power of the experiment is low it's underpowered     
34:58     
then that significance doesn't mean as much as if your experiment were properly     
35:03     
powered and you get a significant result basically that's the idea um then you know they think Theon     
35:11     
elegans ultimately the value of the reverse engineering approach that they propose here will allow us to do this     
35:18     
for their systems so we might be able to scale to other systems like you know uh     
35:23     
fruit flies roopa or you know maybe something like Mouse which you know is     
35:29     
probably well off into the future uh and so this is uh said just     
35:36     
like the sequencing of the first genome enabled by the Human Genome Project and the sequencing of the genomes of many     
35:42     
humans reverse engineering a nervous system promises to open the floodgates to reverse engineering many other     
35:48     
nervous systems so they're using Human Genome Project is sort of a a comparator     
35:55     
here and so needless to say we need to think about generalizing the larger     
36:01     
nervous systems a lot of people in this group are interested in human brains which are much much larger than celegans     
36:07     
produce a much wider range of behaviors which is interesting because you know     
36:13     
it's not uh and and celan's neurons don't really have the same type of     
36:18     
spiking behavior that that Maman neurons do so these are all these challenges in     
36:24     
kind of scaling the up to humans or even to something like Mouse or even really to something like your     
36:30     
soft um but you know that's where they kind of want to go so that's basically     
36:37     
the idea it's a vision paper and those are the references so     
36:42     
that's where they are and I think it's fascinating it's a fascinating kind of     
36:48     
take on this uh I think the main thing that trying to do beyond what like's been     
36:54     
done with openworm is this idea of collecting data for all possible     
37:01     
different behaviors and you can do that in celegans I suppose if you had enough     
37:08     
resources we have enough Community uh tools to say kind of what the basic     
37:14     
behaviors are what the basic neuros responses but then to kind of work all that out into this complete description     
37:20     
is is really where the power is this all right so a few words about these input output functions that they were talking     
37:27     
about about it in the first paper we talked about Ming so uh you know we     
37:33     
talked about this term and I was kind of doing it my notes so I didn't show what I was diag but basically we have out     
37:40     
we're trying to solve for an output and in doing so we have     
37:46     
inputs and we have maybe an additive noise term so the additive noise term would be like you know what's going on     
37:54     
in the brain it maybe like a brain Network where you have input     
38:01     
here which is this term and then an additive noise term which maybe modifies the input in different ways provides     
38:09     
maybe you know ways to dampen the input or accentuate the input or interfere     
38:15     
with the input so we have this noise term plus the input equals the output and then     
38:20     
they talk about maybe a more sophisticated model when for multiple compartments with the second term so of     
38:27     
course we're solving for the output we still have the input term and that could be something like maybe like a light     
38:36     
source and of course we we set a spatio temporal and remember our output is also     
38:43     
spao temporal so we have the output which is a     
38:51     
behavior which is also spatio     
38:56     
temporal and and then we have maybe an additive term here but instead of just     
39:01     
chalking it up to noise we can break this down into a couple of different components so we still have some noise     
39:09     
because you know neural activity often involves a stochastic component Le     
39:14     
component we might also add in maybe something like syap like maybe a weight     
39:20     
Matrix so in a neural network we have a weight Matrix in the brain we might have     
39:26     
synaptic activity and we could summarize that as a weight Matrix and then maybe things like     
39:32     
neuropeptides or like a matrix having to do with neuropeptides we have neuropeptidergic uh connectomes in     
39:40     
cagans that have been drafted so those are all things that we can put into this term and these all kind of maybe your     
39:47     
additive along with the additive component of the input and it gives us the output these can also be     
39:54     
multiplicative as I mentioned all these things can be multiplicative and it has an effect it actually is more     
40:01     
of a nonlinear effect on the system so this is assuming some sort of     
40:07     
linearity or nonlinearity to what happens inside the     
40:13     
brain so the input is of course from the environment and this other term is     
40:20     
internal so we're really trying to predict the internal state which is this     
40:26     
component here this compartment of our mod and the uh environmental component     
40:33     
is summarized as input but we can just as easily break that down as well into     
40:38     
multiple components so we might take our input and break it down into something like a light     
40:44     
source maybe like an odorant maybe like if we're talking     
40:51     
about spaes ship temporal variation maybe it's like a landscape     
40:58     
like there are certain places where you can go certain places where you can't in terms of navigation in terms of     
41:04     
movement and so that's those are all things that are in the input we can actually have a bigger component there     
41:10     
so yeah I hope Morgan found the discussion is paper and lightning I mean     
41:16     
we didn't get to discuss it Saturday actually Saturday we discussed some things about kind of like simulating the     
41:22     
brain so Morgan you had something to say I know I was just going to say that     
41:27     
that um you know what what you said is was kind of um Conrad's pitch you know     
41:36     
and um uh he seems to be trying to raise     
41:41     
money to collect this data right so he was at this meeting because     
41:49     
uh because it's definitely uh Place well he's a he's a foresight     
41:56     
fellow or or you know that that they gotten some money to start this uh on     
42:03     
the basis of a of a foresight Grant and     
42:08     
um and you know it's um it's funny     
42:13     
because somebody who I was going to meet at that meeting had already shared a u     
42:21     
he shared a Conrad paper a Conrad last author paper from     
42:27     
um like 2013 that was like scalable neural     
42:34     
recordings forget that the the title it's in Frontiers um but it's it's it's     
42:42     
uh I said to um you know like my take on that paper was like this was a this was     
42:50     
like a a white paper for the brain initiative you know this 2013 paper you     
42:55     
know and I I I think that was about the right time for it you know but I was     
43:02     
also I mean I I was looking at this 2013 paper and I was just like look at these     
43:07     
people like it's um it's Conrad     
43:12     
cording who you know again I I think it was kind of as a as a a neuro imager uh     
43:19     
you know whole brain f r neur imager and um but he's on this paper with like all     
43:26     
these invasive recording people yeah and and again it just struck me as     
43:32     
a as a brain initiative kind of paper but um it uh it it was useful I mean     
43:42     
again like it was um it was only lightning talks at this Vision weekend     
43:48     
so it was a very short I I think I've got a picture of each of his slides because he only had like eight slides     
43:56     
but but I felt that that the the um the     
44:01     
video that he had from last year excuse     
44:07     
me it was like more like 50 50 minutes and and laying out you     
44:15     
know kind of described G gave a lot more of kind of like his his motivation and and and uh     
44:24     
sort of like how how did someone how did a how did a nice ner imager like     
44:29     
him end up uh proposing to do c Ellen's work yeah and the     
44:39     
um so again it was kind of a combination of of him saying     
44:46     
um uh you know somebody needs to do this right so so one of it was just like i' I     
44:54     
I've tried a I've tried an NSF Grant Center Grant and and we got rejected and     
45:02     
um and again like I look at this paper and I I see a lot of big names on this     
45:10     
paper right and certainly a lot of of you know like like you said like he     
45:15     
seems to have again pulled together a a number of really high-profile people     
45:21     
doing singan work and and you you know with kind of     
45:29     
you know firmy like calculations has put together what you know wants to say is     
45:36     
like this is this is the data that we need to get to kind of you know forward     
45:43     
solve the the yeah neural neural behavior     
45:49     
um and you know was kind of now pitching     
45:54     
a a more like you know I think he said you know like     
46:00     
the center Grant was going to be like 60 million because he was going to lose half to to the institution and you know     
46:08     
he's selling he's selling it to foray people as like a $20 million Grant uh as     
46:15     
maybe like a um focused research organization right where it's like all     
46:20     
all yeah that that's that's the that's the entire entity and um and and yeah     
46:28     
yeah um so that that was that was cool and I think he he he he also threw in     
46:36     
just in our you know pinning him down after um that uh he felt that um it was     
46:46     
time to it was time for him to do something new yeah so he he he was also     
46:54     
like U of the opinion that um you know if things if things start um     
47:02     
start getting stale you know like yeah change you know I mean I wouldn't     
47:09     
exactly call this changing field but he was just like no I'm I'm doing something new now or well again he kept on saying     
47:17     
like I'm trying trying to switch I'm try trying to pull together     
47:23     
and um and yeah so but it was nice it was certainly nice I I'd never uh I never     
47:30     
met him at a at a Nur Imaging conference and um so it was it was certainly nice to     
47:37     
talk to him and see what uh see how he phrased it all um and then you know I I     
47:45     
I don't know if I'd seen this before I mean I feel like I I do follow foresight     
47:52     
like I feel like I should have seen this but um anyway but it was nice and um     
48:01     
uh nobody else you know the other I mean e E11 bio was one of the other speakers     
48:10     
which which is a is a focused research organization that's kind of doing C Atlas     
48:18     
connectomics you know um but but very much like you know somebody came up to     
48:28     
uh while we were talking and was just like hey you know why aren't you looking     
48:35     
at um uh uh zebra fish or something and and     
48:43     
um and he said you know yeah that basically it would it would take too     
48:49     
much data you know like like this wasn't yeah um and this this this was yeah     
48:58     
where where he'd want to start um and and you know I did I did ask a little     
49:05     
bit about um you know how sophisticated was the microscopy like what what kind of     
49:12     
equipment you know kind of Buy in would you need to to be able to collect the kind     
49:19     
of data um that that he wants to do and you know it still seemed pretty highend     
49:27     
um um but but it's also the kind of thing where I'm kind of surprised I mean     
49:34     
yeah like like why isn't or you know I know Jania is doing zebra fish you know     
49:42     
yeah yeah they are and I mean certainly you you know I I when I     
49:48     
remember human the brain initiative being talked about and certainly like     
49:55     
there was this um series of of talks of kind of like tech     
50:00     
people together with neuro people I forget what that little series was     
50:06     
called um but and it was a big it was a     
50:12     
big focus on like scalability it was like we tech people understand     
50:19     
scalability oh yeah so can can can we can we somehow help and I I remember     
50:27     
but I just remember these you know Wonderful whole brain um zebra fish     
50:34     
images yeah um and you know thinking well yeah so     
50:43     
I it was nice it was nice yeah um like you said like Mamon is is way off and     
50:54     
um uh     
50:59     
you know the the the other people were kind of these focused ultrasound groups like Mary Lou japson and some are     
51:09     
um talking about um you know kind of     
51:14     
medical devices so this this was the this was the one kind of real real ambitious uh     
51:23     
yeah seemed like the ambitious neuro project and of course it was the Elegance so I did bring up a I asked him     
51:29     
about openworm and you know but open worm obviously is not a data generating organization right um but uh like you     
51:39     
like you covered there you know fin Bergen at least um understands that     
51:44     
development is is one of those um kind of explanatory perspectives that you     
51:51     
that you still really need to have right um so     
51:57     
uh if I if I could also just add that um I got to have a nice conversation with     
52:04     
Adam saffron okay recently and yeah yeah yeah     
52:10     
at the same meeting okay um so and um     
52:15     
and that was that was very cool um because well one it seems like     
52:23     
he's maybe I mean I think I brought this up that he was pitching at the last one a     
52:29     
kind of um empath empathic uh Ai and it     
52:35     
does seem like he's maybe kind of fundraising for his own AI startup too     
52:43     
um which you know is is the decade apparently um uh and so he'll be going     
52:50     
up to you know nurs for for you know both networking and and potentially     
52:57     
fundraising um but but what was cool was that he said that you know he's     
53:04     
basically Michael Evans Lab now oh okay and um that they are working on um     
53:13     
active inference paper that um that is     
53:19     
you know like active inference in this cellular of of cellular agency right and     
53:26     
and um you know which which certainly sounds like maybe some previous Michael     
53:32     
11an papers that I can think you know when I think of active inferences cell I think maybe Michael Lan's maybe one of     
53:39     
the only people I can think of there couple yeah but yeah well I would love     
53:45     
if you've got any um if you've got any suggestions of others um I'd love to     
53:52     
hear them and um and certainly I I mean I was gonna you     
54:00     
know again this might be Michael Evan covered as well but um I was putting     
54:06     
together a couple references that um     
54:11     
that definitely like kind of embryogenesis and and how that     
54:19     
um how that can be seen as as a kind of Act of inference certainly of of um     
54:26     
responding to um perturbations and things like that yeah and there's this great there's     
54:35     
this great paper um that uh that I love of     
54:41     
um uh estimating kind of the regulome from um spatial transcriptomics     
54:51     
data and speaking to kind of you know large scale     
54:57     
um um yeah these kind of large scale genetic networks and and their their     
55:05     
ability to to provide some of that uh that cellular     
55:14     
inference yeah I'm just reading some notes Here     
55:22     
sure sure yeah oh so yeah that's interest I'm glad that uh Adam's kind of     
55:30     
working on that that sounds great um yeah I think trying to remember I think     
55:36     
the active inference Institute they were working on a paper about development an     
55:41     
active inference and I can't remember the authors in that paper um I think     
55:47     
there are a number of other things that have come out of 11 lab where they've been talking about like embryogenesis     
55:55     
and not so much active inference but kind of like mechanisms     
56:00     
for you know kind of active inference like things it didn't really use the term active influence so it's like you     
56:07     
know you know it's a framework of course that has a formal terminology so maybe     
56:13     
you know that's that's maybe more productive in terms of using the same terminology mapping things to the     
56:21     
terminology uh yeah I think that's really interesting stuff and there's a lot of work like     
56:27     
you know with like genetic networks and gene expression regulatory networks and     
56:32     
expression networks and things where you can look at like you know how they kind of function and you know the I mean there's     
56:40     
a lot there are a lot of active inference principles that could be used there um but that's that's kind of an     
56:45     
open area because I don't think people have really looked too much at that     
56:51     
specific yeah that's I mean and and um this uh that regulon paper is from     
57:01     
um Ro it's like the RO institutes in     
57:07     
basil or Basel whatever but yeah that like like a big like applied organoids     
57:16     
research Group which which I think it's     
57:22     
cool I'm gonna definitely have to start to start shoveling kids in this     
57:29     
sex but but love love that love that you covered that paper and yeah love to follow up on any other uh references you     
57:37     
can think of okay I'll try to put together something for that okay well thanks Morgan for that     
57:46     
discussion um so I I I don't really want to get into the other things that I had because     
57:53     
it's already almost 10 so for the top of the hour so uh I think that's all for     
58:00     
this week uh Susan did you have anything to add or um no not much I read somewhere where     
58:09     
um epithelial cells um are not really an organoid but     
58:16     
that you might get epithelial cells on the outside of an organoid if you were     
58:21     
going to study them but um that they're us usually not studied on     
58:28     
organoids and the measurements I have for some of the uh one of the papers um     
58:36     
did cells on um flat sheet of gel so that that was     
58:42     
interesting that one is a nice one I wish there were more like it because     
58:47     
they actually showed the cells and then showed what they did     
58:53     
so um yeah still still searching for for more     
58:59     
data of course but pretty difficult yeah there's there's things on the lung at     
59:06     
least and um I think these cells were um liver cells and back cells I     
59:15     
guess I should I need to look that up before I hand in the final copy of my paper     
59:23     
here and it's it's almost ready to go so     
59:28     
I'll and in version seven today and they can shred     
59:33     
it I I'm presenting on the 16th okay well good luck yeah that's coming up yes     
59:41     
it's a holiday season presentation How's that gonna work yeah that's     
59:49     
okay that works for me okay well yeah I could right if you'd like to     
59:56     
test it out you know next week or or whatever in the meeting you'd be welcome to do that     
1:00:03     
if um maybe I could test out my verification stuff since that's what's bothering me okay that sounds good yeah     
1:00:12     
okay I'll I'll see if I get what I do I I'm going to put it together I'm going to start putting together my my     
1:00:18     
presentation yeah yeah yeah so okay     
1:00:26     
right thanks thanks talk to everyone next week okay bye bye by okay now I'd     
1:00:34     
like to go over one additional paper and this is this paper here tissues as     
1:00:40     
networks of cells where generative rules of complex organ development so we've     
1:00:45     
talked about generative rules before generative uh models of development and     
1:00:50     
you know everyone's interested in generative AI but generative modeling is a long history     
1:00:56     
in uh Computing in generating things     
1:01:01     
from a bunch of interactions or generating things from say like an algorithm like a genetic algorithm or     
1:01:08     
even like a deeper and it's just basically um you know defining a bunch of Agents or     
1:01:15     
defining a bunch of units and looking at the interactions and what they produce as an     
1:01:22     
output so they're going to use you know we and then we talked about how you can apply those kind of generative     
1:01:29     
computational techniques to development and what development essentially is doing is generating or building a     
1:01:35     
generative model on top of like a gene regulatory Network and that's really giving us this you know we have this     
1:01:42     
environmental input we have the stochastic input and we have the genome     
1:01:48     
and it all combines to produce these generative structures the generative rules so this is where they talk about     
1:01:55     
generative rules rules of complex organ development so these are some authors     
1:02:01     
from the German group uh saine fiser George Bassel and Philip     
1:02:08     
hansburg uh so the the abstract here reads network analysis is a well-known     
1:02:13     
and Powerful tool in molecular biology more recently has been introduced in developmental biology     
1:02:20     
tissues can be readily translated into spatial networks such as cells are represented by noes and intercellular     
1:02:27     
connections by edges so we've talked about these kind of networks before where you know we can build like     
1:02:34     
spatial networks of cells with intracellular     
1:02:39     
edges um so you know it's basically that maybe two cells are communicating maybe     
1:02:45     
they're reinforced by some extracellular Matrix or like we've talked about with     
1:02:51     
our uh our Tri Junctions and our quad     
1:02:56     
Junctions and things like that where you have these meeting points between the cells that confer some sort of stability     
1:03:04     
we talked about this in previous meetings so I won't get into that here     
1:03:09     
uh this discretization of cellular organization enables mathematical approaches rooted in network science to     
1:03:15     
be applied towards the understanding of tissue structure and function in this paper we describe how such tissue     
1:03:22     
abstractions so remember these networks are abstractions of a tissue and enable the principles that underpin tissue     
1:03:29     
formation and function to be uncovered we provide an introduction into biologically relevant Network measures     
1:03:35     
then present an overview of different areas of Developmental biology where these approaches have been applied we     
1:03:42     
then summarize the general developmental rules under underpinning tissue topology generation finally we discuss how     
1:03:49     
generative models can help to link the developmental rules back to the tissue     
1:03:54     
topologies our collection of results points to a general mechanism or a set of General     
1:04:00     
mechanisms as to how local development of rules can give rise to observe topological properties and multicellular     
1:04:10     
systems so they going of talk about how Network approaches can be used to look     
1:04:16     
at the molecular interactions between cells a large number of measures enables     
1:04:21     
the analysis of these networks to understand system function some of these same methods and analyses     
1:04:28     
can be applied addition additional scales of biological complexity looking at the study of cell interactions and     
1:04:34     
tissue so they're taking uh molecular networks as inspiration of course we've done work     
1:04:40     
with cell level networks um and that's very you know that has a similar sort of     
1:04:48     
structure to it a perspective of multicellular systems is interacting collectives of cells can be traced back     
1:04:54     
to the work of mon goal and some of the stuff they would been doing with Maman nervous systems     
1:05:02     
and he drew a lot made a lot of drawings of these wiring diagrams and they very very much map to these Network     
1:05:11     
approaches okay so this is kind of an example here this is one of Ramon Hall's     
1:05:17     
drawings of animal nervous tissue this is a model of celegans and B in roph you     
1:05:24     
can cellularize and you know a microscopy image you can build a model with that um you can also do this in C     
1:05:31     
elegans or tissues and in a rabid opsis you can build models of tissue     
1:05:37     
complexity there so they're looking at different ways you can analyze networks in these different model organisms where     
1:05:44     
you can take data from some source and make build a     
1:05:49     
model so what they're looking at particularly uh is structural networks     
1:05:55     
so so structural networks describe the physical associations between cells this     
1:06:00     
is akin to a road map which captures all the possible routes Cur cars can travel     
1:06:05     
in tissue terms this describes the potential communication between cells functional networks apply contrast     
1:06:12     
describe the observed communication and information flow between cells and tissues the Kinder where traffic is     
1:06:19     
observed in a road Network so they they actually make a distinction between structural and functional Networks so     
1:06:25     
structural networks are where we describe the physical associations between cells so if we look at this     
1:06:31     
figure we see you know the structural associations between neurons are the     
1:06:36     
branching structures here and how they connect to other cells so cell bodies     
1:06:42     
are connected to other cell bodies through these projections and we can map     
1:06:47     
out those relationships in a structural Network a functional Network by contrast     
1:06:53     
is where you look at the between these nodes or these cell bodies and so you     
1:06:59     
want to ask the question we know that these things are connected what subset of these things     
1:07:05     
are actually transferring information or transferring uh chemicals or     
1:07:10     
transferring something from one new to another uh we can think of this as the     
1:07:15     
difference between say like a static Network and a dynamic Network or a you     
1:07:22     
know sort of a description of the structure versus is something like the description of a flow and so these both     
1:07:29     
of these types of networks are important for understanding tissues and integrating them of course is important     
1:07:35     
as well um functional networks are constrained by physical networks so the     
1:07:41     
physical networks provide sort of the you know the full architecture of the uh     
1:07:48     
functional Network the functional network is usually a subset of the physical     
1:07:53     
Network and uh functional networks are also dynamic in the sense that intracellular communication can be     
1:08:00     
modulated across development so these flows or these functions can be modulated in development from you know     
1:08:08     
as as things are becoming connected they kind of Follow that connection but     
1:08:13     
they're not you know not everything is active sometimes uh in development function can reinforc structure so in     
1:08:22     
neurons you know we have this idea that neurons get connected because they get     
1:08:29     
connected with say like uh synapses and you know axonal connections     
1:08:35     
because of previous chemical cues that exist in the environment so the nodes     
1:08:41     
basically send out this chemical signal and then those chemical signals are     
1:08:47     
picked up by other neuron neuronal bodies they send out projections they connect to one another because of some     
1:08:53     
chemical affinity and that's set up a structural Network that then further     
1:08:58     
sets up function at the synaptic level at the um you know so we can have a more     
1:09:04     
refined chemical communication between the cells that's basically the     
1:09:09     
idea and so all of that is hard to represent with just a simple set of     
1:09:14     
nodes and edges you need to have a little bit more uh in that network but     
1:09:20     
but it's basically the same you know you have to distinguish between the structural and functional NS     
1:09:30     
okay so then they talk about biological relevant Network measures and this is kind of interesting because a lot of the     
1:09:38     
complex Network measures that have been proposed have not been proposed specifically for biology so you know a     
1:09:45     
lot of times like things like between the centrality cluster and coefficient     
1:09:50     
shortest path and degree are all artifacts of     
1:09:55     
like call Universal networks that is universal networks are networks that can     
1:10:01     
describe biology but they can also describe social systems they can also describe technological systems they can     
1:10:09     
also describe just about anything else that forms a network any set of interactions between things and so we     
1:10:17     
can have all sorts of networks that form topologies those topologies can be the     
1:10:23     
same they can be described with these statistics but they're not biologically specific they have this universality though that     
1:10:30     
is that you can use these measures and these topologies you can describe them     
1:10:35     
across the wide range of systems now the problem with this of course is that in biology we have specific things     
1:10:41     
happening that we would like to understand that maybe aren't well captured by these basic measures so like     
1:10:48     
shortest path across the network is basically where you go from one edge of the network to the other edge of the     
1:10:54     
network and you calculate out sort of the shortest route or the most efficient     
1:11:00     
path through that networ so that's what we mean by shortest path now is that a     
1:11:05     
description that is you know that that's often a description of any sort of optim     
1:11:11     
optimizing process or optimal process so for example we're interested in the shortest path not because it necessarily     
1:11:19     
describes anything interesting but because it gives us this Criterion for optimality     
1:11:25     
if we have a flow of a chemical or a flow of information what is the shortest path how can it happen in the fastest     
1:11:32     
amount a time and then we can indeed find that path and predict some sort of     
1:11:39     
flow problem is in biology we don't often need to know the shortest path we     
1:11:44     
may need to know the shortest path if we want to know something you know what the optimal paths through the network but     
1:11:51     
sometimes we want to know other kinds of paths longer paths circuitous paths     
1:11:56     
paths that do some specific thing sometimes these things have evolved in ways that aren't optimal and they're     
1:12:03     
suboptimal so we want to understand those as well now some measures like degree are     
1:12:09     
interesting and and relevant because we need to know say like the General Degree     
1:12:14     
of the network so it's you know this is where you have a node and you want to know how many other things it's     
1:12:21     
connected to so that's very useful in a lot of biological Networks and understanding that degree uh yet for     
1:12:28     
each node but also the scale-free behavior of the network which is where you have many different degrees across     
1:12:35     
the network and classes of degree or specific nodes and you know what those     
1:12:40     
look like what those identities of those nodes are and so forth the clustering     
1:12:46     
coefficient of course describes where you get the most connections and so in     
1:12:51     
different parts of the network you have high connectivity another part so the network you have low connectivity and     
1:12:57     
places where you have high connectivity are what we call clustered we can describe with a coefficient that's very     
1:13:02     
interesting from the standpoint of sort of aggregation and of course in biology     
1:13:08     
we're always interested in aggregation especially in tissues we're interested in sort of with where the action is     
1:13:14     
where the communication is happening um you know that sort of thing so that's a good measure then between the centrality     
1:13:22     
is where you have this sort of uh you know how how many paths run through     
1:13:29     
a certain node so it's like how Central is a node in terms of different parts of     
1:13:36     
the network so in this case you have uh these nodes on the edges of the network     
1:13:42     
which have low between the centrality because they're not connecting anything so they're just kind of the terminant a     
1:13:49     
terminal uh nodes in this network you have these other nodes that are medium which means that they connect     
1:13:56     
say one or two uh nodes to in One Direction and the rest of the network in the other     
1:14:02     
direction so they're kind of peripheral and they have a medium between the centrality and then nodes at the middle     
1:14:08     
of the network that can that connect a lot of things to a lot of other things have a high between the centrality so     
1:14:14     
that's actually very interesting in biology especially in tissues because you can see sort of the center of mass     
1:14:21     
of that Network and you know in in like if we're interested in something like tensegrity it might be a good way to     
1:14:28     
look at like where the critical nodes are for maintaining Ultra stability or     
1:14:33     
stability if we take those nodes out do we remove the stability of the network of the structural Network so these are     
1:14:40     
all interesting measures but in um previous work that we've done in the group we proposed that there other     
1:14:47     
measures I'll have to pull up the list of proposed measures I can't remember if     
1:14:52     
we have this in working paper or we have this in one of the papers we published     
1:14:57     
but we we've talked about this in the past and so there these Universal sort of measures that are interesting some     
1:15:05     
are less relevant than others to specifically the biological networks but     
1:15:11     
some specially in development but some are there there are other measures that we can use in this cas     
1:15:25     
so you know like I said before we have this idea of efficiency of Transport     
1:15:31     
that we want to capture in tissues that's important in multicellular networks we might look at local local     
1:15:37     
and Global efficiency measures so we have these local and Global measures we're interested often times not only in     
1:15:45     
the entire network but Al in small compartments of the network and so you     
1:15:50     
know we might be interested in this entire network where we might be interested in this part of the network     
1:15:55     
this local part of the network off to the side the reason we want to do that is because you know if we think about a     
1:16:02     
network is sort of like it could be hierarchical or it could be like Regional where things     
1:16:09     
happen in one part of the tissue move to the center of the tissue and then you know propagate throughout the rest of     
1:16:16     
the tissue that's all sort of a biological control that you can't easily     
1:16:22     
describe by just describing state so if you describe what's happening throughout the network all in     
1:16:29     
one unit like if we said we just want a a network wide measure of     
1:16:34     
something that only describes what's going on globally there are a lot of things that happen locally in different     
1:16:40     
parts of the tissue that can add up or accumulate over time and and result in     
1:16:46     
some Global phenomena like that the tissue like breaks apart or It suffers a     
1:16:52     
massive injury or something like that and we can't can't describe that unless we've described these local processes     
1:16:58     
that have gone on before that that sort of accumulate and give us that result so this local versus global aspect of     
1:17:05     
networks is very important so we have these examples from     
1:17:11     
veropa from human tissues from rabid     
1:17:16     
opsis and uh you know we have these different types of things from bone from     
1:17:23     
the embryo and rabid opsis and from what's going on in roph     
1:17:30     
so in roph epithelia we have this topology where you know we can examine     
1:17:37     
this using network based approaches uh we can use the same type of model we've used in plant     
1:17:44     
epidermis uh you know in in cop epithelia you have very specific     
1:17:49     
structures so we have to establish six neighbors we have the cell division planes that you know we have as growing     
1:17:57     
Network so cells divide and then form nodes those nodes then get connected and this way local division     
1:18:03     
rules lead to complex emergent tissue properties to decipher morphogenetic     
1:18:09     
mechanisms it is however interesting to investigate differences between epithelia for different regions or     
1:18:14     
developmental stages of dropa and to compare those with epithelia from other     
1:18:20     
species so we you know in doing things with development especially you need to     
1:18:26     
have networks that are growing networks this is something we worked on in Google summer code last year we need to have     
1:18:33     
growing networks but we need to have Network models that go beyond just like kind of nodes and edges so we need to     
1:18:40     
have things like you know gradients and uh growing you know growth     
1:18:46     
processes and all these things kind of put together it's not enough just to have nodes and edges we can have hyper     
1:18:53     
nodes of course as we did on did in Google sumar code last year and so all these things need to be put together in     
1:18:59     
sort of this meta model of development ofs um so yeah they talk about dropa     
1:19:07     
epithelium they talk about the connections with some of the things that they're doing in     
1:19:17     
arabidopsis talking about cell differentiation patterns in the mouse embryo and in cancer tissues and so you     
1:19:25     
get these kinds of uh systems where they're     
1:19:30     
heterogeneous they have wide ranging effect sometimes the local structures need to changes in the global     
1:19:37     
structures there's a spatial distribution of of things and tissues that are interesting to consider so you     
1:19:44     
know not every cell is simultaneously doing something you know if you think about the the sir model in epidemiology     
1:19:53     
you get nodes that are effected you get nodes that are recovered uh and you know there's a     
1:19:59     
distribution of those at each time point so it's a dynamic graph that changes over time and there's some process that     
1:20:06     
spreads throughout the network and so you know with cancer you you have a similar situation where cells can become     
1:20:12     
cancerous or they can cancer can spread throughout a tissue you would model that using a sort of Sir model where a cell     
1:20:20     
becomes sort of cancerous or the cancer Le spreads that spatial compr     
1:20:25     
and then you look at how many spatial compartments or the spatial extent of that uh     
1:20:33     
cancer conversion happens and so you can then calculate Network statistics you     
1:20:38     
can calculate local versus global Dynamics and so     
1:20:44     
forth uh they talk about cell division rules here which are you know important for kind of you know for understanding     
1:20:51     
cell division but you have to then use a division rule based on that to sort of     
1:20:57     
understand the topological state of a network so you know again this is     
1:21:03     
something that uh we've kind of considered in our group and um you know     
1:21:10     
this is where you have different ways that a cell divides different things that go into a cell dividing and you can     
1:21:16     
incorporate that into the     
1:21:21     
network so they actually do this uh comparison and Bone where they look at the topological comparison of networks     
1:21:29     
for Lamar bone versus woven bone and so you can see that in uh Lam bone it's     
1:21:38     
less densely connected but with more optimized mechanisms for efficient transport so in woven bone you don't     
1:21:45     
have these efficient transport mechanisms and you also get this uh High     
1:21:51     
between the centrality which is aligned along paths that connect different L and L so Lamer bone is different in a number     
1:21:59     
of ways you can describe those ways in this sort of network     
1:22:08     
analysis and so we have these different developmental rules uh we have the first     
1:22:13     
one is uh where we have mechanical forces acting upon a tissue we have con     
1:22:19     
a resulting constraint of space but at the same time we have cell division so we have have apotosis for cells that     
1:22:27     
kind of squeeze too much and they disappear from the network and the network then has to     
1:22:33     
reconfigure the second rule is the sort of movement leading to shape changes in the network so as cells migrate     
1:22:40     
collectively they kind of stretch out or they move away from one another it stretches the network in different way     
1:22:47     
results in shape changes in the network and topological changes you also get this uh     
1:22:55     
and and C it's an example of neuronal osteocyte topology so these are cells     
1:23:01     
that do various things they can bifurcate and split they can merge they can terminate     
1:23:08     
or they can branch and so the are this is describing the growth cones of osteocytes or     
1:23:15     
neuronal cells where they can do these different things in their formation and     
1:23:21     
they affect how cells will be connected later and so finally getting to the     
1:23:27     
generative models for tissue Network development there are a number of different underlying models as we know     
1:23:33     
we have these different demands of development we have growth we have uh     
1:23:39     
sort of you know removal and addition of nodes we have this uh you know extra     
1:23:46     
Network topology mechanism for uh sort of bootstrapping Developmental change so     
1:23:52     
all these things that we need to incorporate now they propose a number of different types of models here the first     
1:23:57     
one are Markov models so you know describing these processes as discrete     
1:24:04     
markof chain models it describes the evolution of a system as a series of states in which the probability of     
1:24:10     
transitioning to the next state only depends on the current state so you have     
1:24:16     
this sort of model of change that depends on the current state and it produces the next state and so forth in     
1:24:23     
the case of tissue Networks the state of a tissue has been described as a vector of frequencies of no degrees so this is     
1:24:29     
where they talk about tissue networks and how they describe this state hence     
1:24:35     
an entry in the vector contains the frequency of cells with a specific number of neighbors proliferation rues     
1:24:42     
specify the probability of an i sited Mother cell to produce a j-s sited daughter cell and thereby determine the     
1:24:49     
probability for the system of transitioning from one state to an x uh     
1:24:54     
uh so this is where you know we have these rules for producing we have sort     
1:25:01     
of the current state depending on the previous state we could map that to Mother cells producing a daughter cell     
1:25:08     
so the state of the daughter cell is dependent on the Mother cell it's not dependent on the mother of the mother of     
1:25:13     
the Mother cell and this limited amount of memory     
1:25:18     
you know sometimes is is is quite useful there while there are like there's     
1:25:23     
epigenetic memory while you do have like these different aspects     
1:25:29     
of um you know you have to take into account     
1:25:35     
contingencies in development you also have these sort of immediate things that     
1:25:41     
contribute to uh Network Dynamics so you know using a Markov model allows us to remove a lot     
1:25:48     
of like extraneous stuff and just focus on the most important relationships     
1:25:54     
um we also have agent based models that's a second model an agent based model is you know a grid where it     
1:26:01     
represents a complex system a complex set of global behaviors on the interactions of local     
1:26:07     
individual constituent cells so these are a set of autonomous agents you can     
1:26:13     
program with rules those rules that are ex executed at the local level interactions between cells that then     
1:26:21     
kind of allow you Toge Global state so when you look at an agent based model you     
1:26:27     
have each cell operating individually interacting with its neighbors and then producing     
1:26:33     
This Global state that you can observe in the whole in the entirety of the grid of     
1:26:40     
the so they you know they they talk about rules and agent based models which can be discreet such as FAL statements     
1:26:47     
or continuous which are based on differential equations so we can use our differential equations we can use our FAL statements we can derive the those     
1:26:54     
from the Dynamics of cells we can derive those from the Dynamics     
1:27:00     
of the internal workings of the cell like the genome other kinds of     
1:27:07     
interactions and we can do this for all cells and they they provide an input you know a set of inputs and outputs for     
1:27:12     
each cell when they interact in that way so you know we can provide various     
1:27:20     
amounts of spatial detail in an agent based model um and we can take What's Done in agent     
1:27:27     
based models and transfer it to complex networks okay so apart from the basic     
1:27:34     
tissue topology the distribution of s Fates is also a major interest in developmental systems in a centroid     
1:27:41     
model cell fate markers can be added as properties to each cell in this case cell division rules determine how a fate     
1:27:47     
is pass from the mother's cell to the daughter's cell testing different inheritance rules in a centroid model     
1:27:54     
subsequent comparison with experimental death reveals it symmetrically passing on the same fate from mother to daughter     
1:28:01     
best reproduces the self-hate patterns during primitive endoderm differentiation in ICM organes so this     
1:28:08     
is something that um this is Inner Cell Mass organ so this is where they kind of     
1:28:14     
determine some of these rules for the agent based models based on the biology based on how they replicate these sort     
1:28:22     
of global States in different biological systems um so they have these two     
1:28:28     
different versions of agent based model vertex model and the centroid model     
1:28:34     
so basically you have you know you can have the cell as a Vertex you can have     
1:28:40     
the cells s of the centroid and um the let's say in the vertex model each     
1:28:47     
cell is represented as a polygon this corresponds to a tissue Network in which the nodes describe the polygon corners     
1:28:54     
and edges of the polygon sides so this is where we're describing kind of more of the shape of the network and that's     
1:29:02     
the network instead of like interactions between cells forces acting on a cell     
1:29:07     
Encompass cell elasticity and adhesion and subar packing is determined     
1:29:13     
by stationary and stable Network configurations that fulfill a force balance this is the sort of thing we're     
1:29:20     
trying to do with our biotin securitys so there are a lot of things you can use vertex model on a lot of types of     
1:29:26     
problems such as packing geometry uh and then you know in some     
1:29:31     
cases like the drop Wing dis we can look at node degree and some of these processes where the imaginal disc is     
1:29:39     
producing these highly pattern sets of cells that interact in this tissue     
1:29:44     
structure so this is sideways but this is table one and it basically talks about the different types of models the     
1:29:51     
biological question that you can answer with meod the mechanism it's sort of approximating and the modeling approach     
1:29:58     
you might use for this so there are a lot of different types of agent based model marov     
1:30:04     
model uh and other types of centroid models aent based     
1:30:10     
models and of course other types of u u differential equation models such as     
1:30:20     
hybrid grid continuous threedimensional model continuous two dimensional threedimensional model and a meanfield     
1:30:26     
two-dimensional model okay so that's all for that paper and so I think we've covered two papers     
1:30:33     
today that have kind of gone over maybe some of the generative aspects of development but also how we can plug     
1:30:39     
development into more sophisticated models of celegans and how we can     
1:30:45     
produce these sort of Turing complete models of simulating Cs so that's all     
1:30:52     
for today thank you for paying attention and I hope you learns
